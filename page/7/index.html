<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://shartoo.github.com/page/7/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="shartoo">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shartoo.github.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2016-11-10-softmax" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-11-10-softmax/" class="article-date">
  <time datetime="2019-12-23T10:45:59.384Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-11-10-softmax/">softmax函数</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文根据 <a href="http://blog.csdn.net/hejunqing14/article/details/48980321" target="_blank" rel="noopener">softmax函数定义</a><br>整理</p>
<h2 id="softmax函数的定义"><a href="#softmax函数的定义" class="headerlink" title="softmax函数的定义"></a>softmax函数的定义</h2><p>softmax是sigmoid函数的普遍形式，用于多分类。用在输出层，作为一个分类器，表述为多个分类上的概率分布。 softmax函数的常见形式如下：</p>
<p>$$<br>  P(i) =\frac{exp(\theta_i^Tx)}{\sum _{i=1}^Kexp(\theta_i^Tx)}<br>$$</p>
<p>通过softmax函数，可以使得 $P(i)$ 的范围在[0,1]之间。在回归和分类问题中，通常θ是待求参数，通过寻找使得 $P(i)$ 最大的 $\theta_i$作为最佳参数。回顾logistic函数形式</p>
<p>$$<br>  P(i)=\frac{1}{1+exp(-\theta^T_ix)}<br>$$</p>
<p>这个函数的作用就是使得 $P(i)$ 在负无穷到0的区间趋向于0，在0到正无穷的区间趋向于1。同样，softmax函数加入了e的幂函数正是为了两极化：正样本的结果将趋近于1，而负样本的结果趋近于0。</p>
<h2 id="softmax的可以作为最终概率的证明"><a href="#softmax的可以作为最终概率的证明" class="headerlink" title="softmax的可以作为最终概率的证明"></a>softmax的可以作为最终概率的证明</h2><p>虽然Softmax函数得到的是一个[0,1]之间的值，且 $\sum _{i=1}^KP(i)=1$ ，但是这个softmax求出的概率是否就是真正的概率？换句话说，这个概率是否严格等于期望呢？为此在这里进行推导。</p>
<p>假设现在有K个类，样本属于类别 $i$ 的概率为 $ϕ(i),i=1,…,K$ ,由于 $\sum _{i=1}^KP(i)=1$ ,所以只需要 <strong>前K-1</strong>个参数即可：   </p>
<p>$$<br> \phi <em>i =P(y=i,\phi),i=1,…K-1.\quad \phi _k=1-\sum</em>{i=1}^{K-1} \phi _i<br>$$</p>
<p>先引入T(y)，它是一个k-1维的向量，如下所示：</p>
<p>$$<br> T(1)=\begin {bmatrix}<br>  1\ 0\0\0\.\.\0\end{bmatrix}<br>  \quad<br>  T(2)=\begin {bmatrix}<br>   0\ 1\0\0\.\.\0\end{bmatrix}<br>   \quad<br>   …<br>   T(k-1)=\begin {bmatrix}<br>    0\ 0\0\0\.\.\1\end{bmatrix}<br>    \quad<br>    T(k)=\begin {bmatrix}<br>     0\ 0\0\0\.\.\0\end{bmatrix}<br>$$</p>
<p>样本属于第i类则第 $i$ 行元素为1，其余为0，即：$(T(i))i=1$ (注意第i个列的第i行)。因为y只能属于1类，故(y不等于k时)T(y)只有一个元素为1，其余元素都为0，则y的期望为：</p>
<p>$$<br>  E(T(y))_i=P(y=i)=\phi_i,i\neq K<br>$$</p>
<p>令 $\beta_i=log\frac{\phi_i}{\phi_K},i=1,…,K$(同时除以     $\phi_K$ ),则有:</p>
<p>$$<br>  e^{\beta_i}=\frac{\phi_i}{\phi_K}\Longrightarrow\phi_K=\frac{\phi_i}{\beta_i}\Longrightarrow\phi_K\sum_i^Ke^{\beta_i}=\sum_i^K\phi_i=1<br>$$</p>
<p><strong>注意观察：第三个式子是在第一个式子的左右乘以 $\phi_K$ ,然后累加求和。（第二个式子用在第二步）</strong></p>
<p>所以：</p>
<p>$$<br>  \phi_k=\frac{1}{\sum_{i=1}Ke^{\beta _i}}<br>$$</p>
<p>此时再将 $\phi_K=\frac{\phi_i}{\beta}$ 带入（上面推导的第二个式子），有：</p>
<p>$$<br>  \phi_i=\frac{e^{\beta_i}}{\sum_{i=1}^Ke^{\beta_i}}<br>$$</p>
<p>由于分母中是求和操作，可以将i换成K。得到</p>
<p>$$<br>  \phi_i=\frac{e^{\beta_i}}{\sum_{k=1}^Ke^{\beta_k}}<br>$$</p>
<p>所以实际的期望是具有softmax函数的形式的，当 $f_i(x)=\beta_i=log\frac{\phi_i}{\phi_k}$ 时实际期望与softmax函数严格相等，所求概率为真实值。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-11-10-softmax/" data-id="ck4ifp1lz001z2wje2nol567w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-11-06-deepfeedforwardnn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-11-06-deepfeedforwardnn/" class="article-date">
  <time datetime="2019-12-23T10:45:59.376Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-11-06-deepfeedforwardnn/">深度学习：深度前馈网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一-如何理解"><a href="#一-如何理解" class="headerlink" title="一 如何理解"></a>一 如何理解</h2><p> 前馈网络之所以称为网络，是因为它们是由多种不同函数组成。网络模型可以看做一个有向无环图，该图描述了函数之间是如何关联的。<br> 例如，我们有三个函数 $f^{(1)},f^{(2)},f^{(3)}$ 链式相连，形成 $f(x) =f^{(3)}(f^{(2)}(f^{(1)}))$ ，这种链式结构是神经网络中最常用的结构。其中 $f^{(1)}$ 被称为网络的第一层，$f^{(1)}$ 称为第二层…链式的长度即为网络的深度，网络的最后一层为输出层，这也是深度学习的来源。</p>
<p> 网络训练过程中，我们让 $f(x)$ 逐渐匹配 $f^<em>(x)$ (为我们需要拟合的函数) 。训练样本提供了由  $f^</em>(x)$ 在不同点的带有噪音的近似的样本。每个样本 $x$ 都有一个相对应的标签 $y\sim f^*(x)$  ，训练样本直接指明了输出层在每个点 $x$ 的行为，它应该输出一个近似于 $y$ 的输出。</p>
<h2 id="二-示例：学习XOR"><a href="#二-示例：学习XOR" class="headerlink" title="二 示例：学习XOR"></a>二 示例：学习XOR</h2><p>  我们通过一个学习XOR函数的任务来让前馈网络的概念更具体。XOR函数是一个在两个二值变量 $x_1,x_2$ 上的操作。当 $x_1,x_2$ 中的某一个值为1时，XOR函数返回1，否则返回0。XOR函数提供了一个目标函数 $y=f^<em>(x)$ 。我们的模型提供了函数 $y=f(x;\theta)$ ，我们的学习算法将会逐步调整参数 $\theta$  来使得 $f$ 尽可能地趋近于 $f^</em>$。</p>
<p>  此实例中，我们的目标是使得网络能够正确的预测变量 $x_1,x_2$ 在全部的域值空间的四个点 $X={[0,0]^T,[0,1],[1,0],[1,1]}$。可以将此问题看做回归问题，选择均方误差作为损失函数，在全部训练数据集中，MSE(均方误差)损失函数如下:</p>
<p>  $$<br>    J(\theta) = \frac{1}{4}\sum_{x\epsilon X}(f^*(x)-f(x;\theta))^2 \tag {6.1}<br>  $$</p>
<h3 id="2-1-模型"><a href="#2-1-模型" class="headerlink" title="2.1 模型"></a>2.1 模型</h3><p>  此时我们需要选择模型的形式 $f(x;\theta)$。假若我选择了一个线性模型，其中 $\theta$ 由 $w$ 和 $b$ 组成。我们的模型定义如下</p>
<p>   $$<br>     f(x;w,b) = x^Tw+b<br>   $$</p>
<p>将四个训练样本带入可求解得 $w=0,b=1/2$ 此时的线性模型将一直输出0.5。 下图演示了线性模型无法表述 XOR函数。</p>
<p><img src="/images/blog/dnn1.png" alt=""></p>
<p>图中四个点是学习函数需要在四个坐标输出的值（左下点坐标是(0,0)，要输出0），从左边可以看出线性模型无法实现XOR功能。图右是被神经网络抽取特征的变换空间，此时线性模型可以解决XOR问题了。在样本解中，输出值为1的两个点在特征空间中合并为一个点了</p>
<p>下图演示了一个包含了一个隐藏层（有两个神经元）的网络(之前只有两层，输入和输出)，隐藏层神经元的作用函数 $h$ 为 $f^{(1)}(x;w,c)$ ,隐藏单元的输出将作为第二层的输入。输出层依然是一个线性回归模型，但是它作用对象是 $h$  而不是之前的直接的 $x$ 了。</p>
<p><img src="/images/blog/dnn2.png" alt=""></p>
<p>网络此时包含两个链式函数，$h=f^{(1)}(w;w,c)$ 和 $y=f^{(2)}(h;w,b)$ 。完整的模型可以表述为:</p>
<p>$$<br>   f(x;W,c,w,b) =f^{(2)}(f^{(1)}(x))<br>$$</p>
<p>此时，函数 $f^{(1)}$ 该如何计算呢。如果使用线性模型，将会导致整个网络都沦为输入的线性函数（ $f^{(2)}$(x) 是线性回归）。假若 $f^{(1)}(W^Tx)$ 而 $f^{(2)}(h)=h^Tw$ ，此时整个网络可以表述为 $f(x)=w^TW^Tx$  依然是线性的。</p>
<p>很显然，我们必须使用一个非线性函数来描述这些特征。大多数神经网络是通过一个由学习参数控制的映射转换，加上一个固定的称为激活函数的非线性函数。大多数网络选用 ReLU作为激活函数</p>
<h3 id="2-2-ReLU激活函数"><a href="#2-2-ReLU激活函数" class="headerlink" title="2.2 ReLU激活函数"></a>2.2 ReLU激活函数</h3><p> ReLU作为激活函数的依据是，生物的稀疏激活性。人脑神经元同时被激活的只有1%-4%，这可提高学习精度，更好更快地提取稀疏特征。ReLU的<strong>非线性</strong>来源于神经元的部分选择性激活。</p>
<p> 使用ReLU的另一个原因是，Sigmod（另外一种激活函数）网络会出现梯度消失情况。误差反向传播时，梯度</p>
<p> $$<br>   Gradient = (y-y^{‘})sigmod^{‘}*x \<br>   sigmod^{‘}(x) \quad\quad\epsilon (0,1) \<br>   x \quad \epsilon (0,1)<br> $$</p>
<p> 会成倍衰减（ $sigmod^{‘}(x) \quad\epsilon (0,1)$ ,$x\epsilon (0,1)$）。而ReLU的梯度为 $max{0,W^Tx+b}$ 始终为1，只有一端饱和，梯度易流动，同时提高了训练速度。</p>
<p> 关于ReLU的详细可参考 <a href="http://www.cnblogs.com/neopenx/p/4453161.html" target="_blank" rel="noopener">ReLU激活函数</a></p>
<h2 id="三-基于梯度的学习"><a href="#三-基于梯度的学习" class="headerlink" title="三 基于梯度的学习"></a>三 基于梯度的学习</h2><p> 神经网络的非线性将导致损失函数非凸，没法全局收敛。应用于非凸的损失函数的SGD（随机梯度下降）方法也无法全局收敛，而且对初始值敏感。对于<strong>前馈网络而言，初始权重应随机初始化为很小的值，偏置 $b$ 初始化为0，或很小的值</strong>。 梯度下降方法应用在各种网络中，用来最小化损失函数。其实在训练SVM，线性回归模型中都可以使用梯度下降方法</p>
<h3 id="3-1-损失函数"><a href="#3-1-损失函数" class="headerlink" title="3.1 损失函数"></a>3.1 损失函数</h3><p>设计神经网咯时，一个重要的组成部分是损失函数的选择，尽管大部分神经网络的损失函数都与参数模型相似。</p>
<p>大多数情况下，参数模型的定义了一个概率分布 $p(y|x;\theta)$ ,我们使用的是最大似然定理（深度学习，机器学习的本质，将训练时最优的参数当做实际最优的参数），即，使用训练数据和模型预测值的交叉熵作为损失函数。</p>
<p>交叉熵定义：</p>
<p>$$<br>  c = -\frac{1}{n}\sum_{x}[ylna+(1-y)ln(1-a)]<br>$$</p>
<p>交叉熵特性:</p>
<ul>
<li>非负性</li>
<li>期望与实际误差小时，损失值小，反之则大。</li>
</ul>
<p>有时候我们会使用一种简化解，不使用全部的 $y$的概率分布，仅预测满足一定条件的x对应的输出y的概率分布。</p>
<h4 id="3-1-1-1-学习条件最大似然的条件分布"><a href="#3-1-1-1-学习条件最大似然的条件分布" class="headerlink" title="3.1.1.1 学习条件最大似然的条件分布"></a>3.1.1.1 学习条件最大似然的条件分布</h4><p> 使用最大似然方法训练网络，其损失函数即负的对数似然，可定义为</p>
<p>$$<br>  J(\theta) = -E_{x,y\sim p^{\sim}<em>{data}}logp</em>{model}(y|x)<br>$$</p>
<p>不同的参数模型，具体的损失函数不一样。</p>
<p>线性模型的输出的概率分布的最大似然估计等价于最小均方误差（损失函数的一种），实际上，这种等价是以忽略 $f(x;\theta)$ 对高斯分布的均值预测为前提的。</p>
<p>设计神经网络时的一个常见问题是：梯度需要足够大，且易于预测。饱和函数（上面一章中ReLU参考文章中有解释饱和函数）会破坏这一期望，它会将梯度变得特别小，这会导致网络很难调整。如果网络输出层是 $e^x$ 类的函数，若 $x$ 为较小负数，也会饱和。在这样的函数上应用对数函数可以有效化解饱和问题（对数和 $e^x$ 相互抵消）。</p>
<p>交叉熵损失函数可用来完成类似的最大似然估计的功能，因为它没有最小值，但可以无限逼近于0或1，这可同时用于离散化输出，logistic回归就是一个类似的模型。<strong>问题</strong>：若模型可控制输出分布的密度，就有可能给正确的训练集极高的密度，这会使得交叉熵趋于无穷大，使用正则化可用来避免这个问题。</p>
<h4 id="3-1-1-2-学习条件概率"><a href="#3-1-1-2-学习条件概率" class="headerlink" title="3.1.1.2 学习条件概率"></a>3.1.1.2 学习条件概率</h4><p>相比于 $p(y|x,\theta)$ 的完全概率分布，我们一般仅学习一个给定$x$ 的 $y$ 的条件概率分布。假若我们使用一个足够强大的网络，我们可以认为网络能够表述任意函数 $f$ (函数有足够多的分类),此时函数的分类仅受限于特征，比如特征的连续性和无界性，而不是某种固定的参数形式。从这个视角来看，我们可以将损失函数视为<strong>函数式</strong>而非简单的<strong>函数</strong>。<strong>函数式</strong>指的是从函数到实数的映射，而学习过程将会是选择一个函数，而不是一系列参数。此时，我们设计<strong>损失函数式</strong>为在某些期望函数上才取得最小值。比如，我们设计的损失函数式取得最小值的时候，对于给定的特征 $x$ 刚好输出了期望的 $y$ 。</p>
<h3 id="3-2-输出神经元"><a href="#3-2-输出神经元" class="headerlink" title="3.2 输出神经元"></a>3.2 输出神经元</h3><p> 损失函数的选择与输出神经元的选择直接相关。下文简述了一些不同输出分布时对应的神经元。</p>
<h4 id="3-2-1-高斯分布输出的线性神经元"><a href="#3-2-1-高斯分布输出的线性神经元" class="headerlink" title="3.2.1 高斯分布输出的线性神经元"></a>3.2.1 高斯分布输出的线性神经元</h4><p> 对于给定特征 $h$ ，线性输出神经元的输出为 $\bar y =W^Th+B$ 。线性输出层通常用来生产条件高斯分布的均值，此时求对数似然的最大值等价于最小化均方误差。(方差越小，分布越集中)。</p>
<p> 最大似然框架易于学习高斯分布的方差，使得高斯分布的协方差成为输入的一个函数。但是所有的输入其输出必须为正的有限的矩阵。</p>
<h4 id="3-2-2-Bernoulli输出分布的Sigmoid神经元"><a href="#3-2-2-Bernoulli输出分布的Sigmoid神经元" class="headerlink" title="3.2.2 Bernoulli输出分布的Sigmoid神经元"></a>3.2.2 Bernoulli输出分布的Sigmoid神经元</h4><p>许多二分类问题都可以使用Sigmoid神经元输出。最大似然估计的方法是定义一个在条件 $x$ 上的 $y$ 的Bernoulli分布。</p>
<p>定义Bernoulli 分布只需要一个参数（概率），神经网络只需预测概率 $P(y=1|x)$ 即可。假若使用线性激活神经元，网络输出的预测概率</p>
<p>$$<br>  P(y=1\mid x) =max \lbrace 0,min\lbrace 1,w^Th+b\rbrace \rbrace<br>$$</p>
<p>其中 $w^Th+b$ 很容易就不在区间 [0,1]上，为0.梯度为0，如何保证一直有较强的梯度呢？我们选用 Sigmoid 作为激活函数即可。Sigmoid激活神经元的输出为</p>
<p>$$<br>  \bar y = \sigma (w^Th+b)<br>$$</p>
<p>而 $\sigma (x) =\frac{1}{1+e^{-x}}$ 。我们可以把 $sigma$ 输出单元看做两个组成部分：1.第一步是一个线性层，计算输出 $z= w^Th+b$ 即可。2. 使用<strong>Sigmoid</strong>将输出 $z$ 转换为概率。</p>
<p>我们考虑如何使用上面提到的 $z$ 来定义 $y$ 上的概率分布。我们可以通过构建一个非正态概率分布 $\tilde p(y)$(概率和不等于1)来理解 <strong>Sigmoid</strong>。下面是公式推导过程:</p>
<p>先假设对数概率在y,z上是线性</p>
<p>$$<br>  log\tilde p(y)=yz \quad \<br>$$</p>
<p>取指数得非正态概率</p>
<p>$$<br>  \tilde p(y)  =exp(yz)<br>$$</p>
<p>对每个概率除以总概率即可归一化（概率和为1）</p>
<p>$$<br>  p(y) =\frac{exp(yz)}{\sum^1_{y’=0}exp(y’z)}<br>$$</p>
<p>通过对 $z$ 的Sigmoid转换，获取一个Bernoulli分布</p>
<p>$$<br> p(y) =\sigma ((2y-1)z)<br>$$</p>
<p>此方法来预测对数空间的概率可以用最大似然方法。因为最大似然的代价函数是 $-log p(y\mid x)$ ，这个对数log 移除了Sigmoid中的指数式exp。如果没有这一步，sigmoid的饱和性会阻止梯度学习。</p>
<p>使用sigmoid参数化的Bernoulli分布的最大似然学习过程的损失函数如下:</p>
<p>$$<br> J(\theta) = -log P(y\mid x) \<br> =-log \sigma ((2y-1)z) \<br> =\varsigma ((2y-1)z)<br>$$</p>
<p>重写softplus损失函数中的部分项，我们可以看到当(1-2y)z，是负数且很大时，损失函数loss才会饱和。<strong>只有当模型基本准确时，才会出现饱和现象，其中 $y=1$ 时，z将会是很大的正数(very positive), $y=0$ 时，z是很小的负数(very negative)</strong>。如果使用其他损失函数，如均方差， $\sigma (z)$ 饱和时，损失函数就会饱和。</p>
<h4 id="3-2-3-多重Bernoulli分布Softmax输出神经元"><a href="#3-2-3-多重Bernoulli分布Softmax输出神经元" class="headerlink" title="3.2.3  多重Bernoulli分布Softmax输出神经元"></a>3.2.3  多重Bernoulli分布Softmax输出神经元</h4><p>softmax是sigmoid函数的普遍形式，用于多分类。用在输出层，作为一个分类器，表述为多个分类上的概率分布。 softmax函数的常见形式如下：</p>
<p>对于二分类变量，我们一般只产生单一输出（两个分类，输出某个分类的概率）。公式:</p>
<p>$$<br>  \hat y=P(y=1\mid x) \quad \epsilon (0,1)<br>$$</p>
<p>上式<strong>值区间为(0,1)</strong>，如果想让此值的<strong>log对数</strong>能在基于梯度的算法中应用，我们选择预测一个值 $z=log \tilde P(y=1 \mid x)$ (概率的log对数)。指数化和归一化，外加一个Sigmoid函数，即可得到一个Bernoulli分布。</p>
<p><strong>推广</strong>：假若我们将其推广到有<strong>n个离散值</strong>的场景中，输出向量 $\hat y$ ，其中 $\hat y$ 中每个分量 $\hat y_i=P(y=i \mid x)$ 取值区间为(0,1)，向量各分量之和为1。一个线性层预测的<strong>非正态对数概率</strong>为: $z=W^Th+b$ ，其中 $z_i=log \tilde P(y=i \mid x)$</p>
<p>$$<br>  P(i) =\frac{exp(\theta_i^Tx)}{\sum _{i=1}^Kexp(\theta_i^Tx)}<br>$$</p>
<p>通过softmax函数，可以使得 $P(i)$ 的范围在[0,1]之间。在回归和分类问题中，通常θ是待求参数，通过寻找使得 $P(i)$ 最大的 $\theta_i$作为最佳参数。回顾logistic函数形式.</p>
<p>对于logistic simoid，使用最大似然框架来训练softmax输出目标y时，exp函数效果很好。此时我们期望最大化 $log\quad P(y=i;z)=log\quad softmax(z)_i$ ，将softmax定义为指数形式是因为最大虽然估计中的log可以抵消。比如:</p>
<p>$$<br> log\quad softmax(z)_i=z_i-log\sum_iexp(z_j)<br>$$</p>
<p>最大化此等式即最大化 $z_i$,后面一项 $log\sum _iexp(z_j)$ 不显著。最大化此等式时，会使得 $z_i$ 增大，而其他所有 $z$ 变小。</p>
<p><strong>通过近似，我们发现负的对数似然损失函数会惩罚大部分错误的激活函数。</strong></p>
<h3 id="3-2-4-softmax评价"><a href="#3-2-4-softmax评价" class="headerlink" title="3.2.4 softmax评价"></a>3.2.4 softmax评价</h3><p> 除了对数似然目标函数外，许多目标函数与softmax搭配效果不好，尤其是那些没有使用Log来抵消指数部分的。</p>
<p> 如果损失函数没有设计好，将导致网络很难学习，在某些区域网络的学习速度极慢。以神经网络的角度来看，softmax实际上是创建了一个竞争环境，总和为1，一方增加时会导致其他所有减少，极端情况下某一方为1，其他全为0.</p>
<h3 id="3-2-5-其他输出神经元"><a href="#3-2-5-其他输出神经元" class="headerlink" title="3.2.5  其他输出神经元"></a>3.2.5  其他输出神经元</h3><p> 最大似然框架指导如何根据输出层来设计一个好的损失函数。如果定义了一个条件分布 $P(y\mid x;\theta)$ 则建议使用 $logP(y\mid x;\theta)$ 作为损失函数。</p>
<p> 通常，我们可以将神经网络看做函数 $f(x;\theta)$ 的表述，函数输出不会直接预测 $y$ 的值，而是提供 $y$ 分布上的参数，此时的损失函数为 $-logp(y;w(x))$。</p>
<h2 id="3-3-隐藏神经元"><a href="#3-3-隐藏神经元" class="headerlink" title="3.3 隐藏神经元"></a>3.3 隐藏神经元</h2><p>隐藏神经元的设计并没有权威的指导原则。一般选择Relu作为隐藏神经元的激活函数。隐藏神经元的激活函数需要不断去尝试，无法预知使用哪种激活函数最好。</p>
<p>有些神经元的激活函数并不是严格可微的，比如Relu在 $z=0$ 时不可导（只是在部分点上）。而实际应用梯度方法依然表现很好，因为训练算法不会使损失函数达到局部最小，而只是大幅度减小。</p>
<p>神经元中的激活函数一般有左右导数，Relu中 $z=0$ 处左导数为0，右导数为1。但是程序实现时，一般只返回单侧导数，而且即便我们在求 $g(0)$ 的值，也只是逼近0的极小值，不是真的 $x=0$时的值。所以，实际上我们可以放心地无视激活函数中的不可微点。</p>
<h3 id="3-3-1-Relu神经元和其泛化"><a href="#3-3-1-Relu神经元和其泛化" class="headerlink" title="3.3.1 Relu神经元和其泛化"></a>3.3.1 Relu神经元和其泛化</h3><p>可以参考两篇博客</p>
<p><a href="http://www.cnblogs.com/neopenx/p/4453161.html" target="_blank" rel="noopener">Relu激活函数，全面</a></p>
<p><a href="http://blog.csdn.net/lg1259156776/article/details/48379321" target="_blank" rel="noopener">Relu，更学术，前沿</a></p>
<p> Relu线性神经元的激活函数为 $g(z)=max\lbrace 0,z \rbrace$ 。</p>
<p> Relu与线性神经元很像，唯一的不同是，Relu的输出取值范围有一半为0（非激活）。这使得其导数一直很大，梯度不仅大而且连续。激活的神经元的二阶导数几乎处处为0，一阶导数处处为1。</p>
<p> <strong>Relu一般用在外层映射，比如 $h=g(W^Tx+b)$ 。初始化Relu时，建议取较小的b</strong>，这会使得Relu对大部分输入都是激活的。</p>
<p> 缺点：激活函数输出为0时（ $z_i&lt;0$ ），Relu无法通过梯度学习，需要做一个泛化补充。<br> $z_i&lt;0$ 时使用一种基于非0的斜率 $\alpha _i$ 来作变换，Relu变为:</p>
<p> $$<br>  h_i=g(z,\alpha)_i=max(0,z_i)+\alpha_imin(0,z_i)<br> $$</p>
<p> 有如下三种方法:</p>
<ul>
<li><p>绝对值Relu:令 $\alpha_i=-1$，那么 $g(z)=\mid z\mid$ 。可以用在图像识别中寻找极性反转时特征不变的特征。</p>
</li>
<li><p>leaky Relu:令 $\alpha =0.001$ 取一个较小值。</p>
</li>
<li><p>参数化Relu:将 $\alpha$ 作为一个可以学习的参数。</p>
</li>
</ul>
<h2 id="3-4-其他隐藏神经元"><a href="#3-4-其他隐藏神经元" class="headerlink" title="3.4 其他隐藏神经元"></a>3.4 其他隐藏神经元</h2><p> 许多未公开发表的激活函数其实与现在流行的激活函数一样有效。比如 $h=cos(Wx+b)$ 在 <strong>MNIST</strong>数据集上错误率只有1%，这完全可以媲美于使用多种卷积激活函数。通常情况下只有当新的隐藏神经元能够取得非常大提升时才会被公开发表。</p>
<p> 神经网络中某些层可以使用纯线性激活函数，有助于减少网络参数。softmax一般用在输出层，但是也可以用于隐藏层。</p>
<p> 其他可使用的隐藏层激活函数：</p>
<ul>
<li><p>Radial basis function（RBF）：$h_i =exp(-\frac{1}{\sigma <em>i^2\mid \mid W</em>{:,i}-x\mid \mid ^2})$ 。只有当x接近于模板 $W_{:,i}$ 时函数才会被激活，由于其对大多数的x都是饱和状态，所以很难优化。</p>
</li>
<li><p>softplus ：$g(a)=\varsigma (a)=log(1+e^a)$ 是Relu的平滑版本，通常不鼓励使用softplus。</p>
</li>
<li><p>Hard tanh：形状与tanh和Relu很像，但是与Relu不同的是，它是有界的。 $g(a)=max(-1,min(1,a))$ 。</p>
</li>
</ul>
<h2 id="3-5-网络架构设计"><a href="#3-5-网络架构设计" class="headerlink" title="3.5 网络架构设计"></a>3.5 网络架构设计</h2><p>网络架构设计关乎，需要多少个神经元，神经元之间是如何连接等问题。网络由一层层的神经元组成，每层由一组神经元构成。假设我们有第一层网络</p>
<p>$$<br>  h^{(1)}=g^{(1)}(W^{(1)T}x+b^{(1)})<br>$$</p>
<p>其中 $x$ 为网络输入， $g^{(1)}$ 为第一层的激活函数。网络的第二层如下</p>
<p>$$<br>  h^{(2)}=g^{(2)}(W^{(2)T}h^{(1)}+b^{(2)})<br>$$</p>
<p>其中 $h^{1}$ 为第一层的输出。</p>
<p>在这种链式结构中，<strong>网络架构需要考虑的是网络的深度和宽度</strong>,一般，更深的网络需要更少神经元，更少参数，但是难以优化。</p>
<h3 id="3-5-1-通用近似属性和深度"><a href="#3-5-1-通用近似属性和深度" class="headerlink" title="3.5.1 通用近似属性和深度"></a>3.5.1 通用近似属性和深度</h3><p>通用近似定理表明，使用 至少一个隐藏层和线性输出层，以及激活函数的神经网络可以拟合任意Borel测度的函数。</p>
<p>多层前馈网络能表述任意函数，但是不能保证我们的训练算法可以学习此函数。有两个如下原因：</p>
<ul>
<li>用来训练的优化函数，可能无法找到拟合目标函数的正确参数。</li>
<li>训练算法有可能因为过拟合选择错误的函数。</li>
</ul>
<p>给定任意函数，必然存在可以拟合的神经网络，但是目前并没有一种通用的方法来校验特定训练样本和函数来泛化不在训练集中的数据点。</p>
<p>广义近似定律表明，存在一个大网络可以拟合任意准确率的预测函数，但是没有提及网络究竟会有多大。最新论文表明，最坏情况下，有隐藏层指数级数量的复杂度。比如一个向量 $V\epsilon \lbrace 0,1 \rbrace$ 上的可能的2分类函数有 $2^{2^n}$ 个，存储这些函数需要 $2^n$ 字节。</p>
<p>在选择机器学习算法时，其实我们是在表述算法所需要学习哪种先验知识。在选择深度学习模型时，其实是在将一个函数表述为几个简单的函数组合，此时学习问题变为挖掘变量间隐藏的关联参数问题，而这可进一步分解为更简单的变量之间的参数问题。</p>
<h3 id="3-5-2-其他架构考虑"><a href="#3-5-2-其他架构考虑" class="headerlink" title="3.5.2  其他架构考虑"></a>3.5.2  其他架构考虑</h3><p> 在设计网络时，需要明白不同的网络有不同用途，比如CNN用于图像处理，RNN用于做序列处理。网络也不必完全链式，从第 $i$ 层网络直接连接到第 $i+3$ 层这样的跳跃，使得梯度更容易从输出反馈到输入。</p>
<p> 另外一个需要考虑的问题是，网络之间是如何连接的。默认是一个以矩阵 $w$ 的全连接，许多网络只是部分连接。比如CNN中用于图像处理，此时参数更少，计算速度快，这与具体问题相关。</p>
<p> <img src="/images/blog/dfn1.jpg" alt=""></p>
<p> 上图显示的是一个参数数量与测试准确率之间的关系。图中显示，<strong>增加CNN的参数而不增加深度并不能提升性能</strong> 。浅层网络在参数达到2000万时过拟合而深层网络在参数达到6000万时性能更强。表明，<strong>网络应该由更多更简单的函数组成。</strong></p>
<h2 id="4-反向传播算法"><a href="#4-反向传播算法" class="headerlink" title="4 反向传播算法"></a>4 反向传播算法</h2><p>后向传播算法并不是指整个网络，<strong>它只是计算梯度的一个方法，有其他方法，如随机梯度下降，它还可以用于对任意函数求导</strong>。</p>
<p>以下解释来自知乎 <a href="https://www.zhihu.com/question/27239198?rf=24827633" target="_blank" rel="noopener">反向传播算法</a></p>
<p>假若我们有如下简单网络：</p>
<p><img src="/images/blog/dfn2.png" alt="简单神经网络"></p>
<p>对应的函数表达式如下:</p>
<p>$$<br> a_1^{(2)}=f(W_{11}^{(1)}x_1+W_{12}^{(1)}x_2+W_{13}^{(1)}x_3+b_1^{(1)}) \</p>
<p> a_2^{(2)}=f(W_{21}^{(1)}x_1+W_{22}^{(1)}x_2+W_{23}^{(1)}x_3+b_2^{(1)}) \</p>
<p> a_3^{(2)}=f(W_{31}^{(1)}x_1+W_{32}^{(1)}x_2+W_{33}^{(1)}x_3+b_3^{(1)}) \</p>
<p> h_{W,b}(x)=a_1^{(3)}=f(W^{(2)}<em>{11}a_1^{(2)}+W</em>{12}^{(2)}a_2^{(2)}+W_{13}^{(2)}a^{(2)}_3+b_1^{(2)})<br>$$</p>
<p>上面式中的 $W_{ij}$ 就是相邻两层神经元之间的权值，它们就是深度学习需要学习的参数，也就相当于直线拟合 $y=k*x+b$ 中的待求参数k和b。</p>
<p>和直线拟合一样，深度学习的训练也有一个<strong>目标函数</strong>，这个目标函数定义了什么样的参数才算一组“好参数”，不过在机器学习中，一般是采用 <strong>成本函数（cost function)</strong>，然后，训练目标就是通过调整每一个权值 $W_{ij}$ 来使得cost达到最小。cost函数也可以看成是由所有待求权值 $W_{ij}$ 为自变量的复合函数，而且基本上是非凸的，即含有许多局部最小值。但实际中发现，采用我们常用的梯度下降法就可以有效的求解最小化cost函数的问题。</p>
<p>梯度下降法需要给定一个初始点，并求出该点的梯度向量，然后以负梯度方向为搜索方向，以一定的步长进行搜索，从而确定下一个迭代点，再计算该新的梯度方向，如此重复直到cost收敛。那么如何计算梯度呢？</p>
<p>我们把cost函数定义为 $H(W_{11},W_{12},W_{13},..W_{ij},..,W_{mn})$ ,那么它的梯度向量就等于</p>
<p>$$<br>   \triangledown H=\frac{\partial H}{\partial W_{11}}e_{11}+…\frac{\partial H}{\partial W_{mn}}e_{mn}<br>$$</p>
<p>此，我们需求出cost函数H对每一个权值 $W_{ij}$ 的偏导数。而BP算法正是用来求解这种多层复合函数的所有变量的偏导数的利器。我们以求 $e=(a+b)*(b+1)$ 的偏导为例。它的复合关系画出图可以表示如下：</p>
<p><img src="/images/blog/dnn3.png" alt="简单神经网络"></p>
<p>在图中，引入了中间变量c,d。</p>
<p>为了求出a=2, b=1时，e的梯度，我们可以先利用偏导数的定义求出不同层之间相邻节点的偏导关系，如下图所示。</p>
<p><img src="/images/blog/dnn4.png" alt="简单神经网络"></p>
<p>利用链式法则我们知道:</p>
<p>$$<br>  \frac{\partial e}{\partial a}=\frac{\partial e}{\partial c}\frac{\partial c}{\partial a} \</p>
<p>  \frac{\partial e}{\partial b}=\frac{\partial e}{\partial c}\frac{\partial c}{\partial b}+\frac{\partial e}{\partial d}\frac{\partial d}{\partial b}<br>$$</p>
<p>链式法则在上图中的意义是什么呢？其实不难发现， $\frac{\partial e}{\partial a}$ 的值等于从 $a$ 到 $e$ 的路径上的偏导值的乘积，而 $\frac{\partial e}{\partial b}$ 的值等于从 $b$ 到 $e$ 的路径 $1(b-c-e)$ 上的偏导值的乘积加上路径 $2(b-d-e)$ 上的偏导值的乘积。也就是说，对于上层节点p和下层节点q，要求得 $\frac{\partial p}{\partial q}$ ，需要找到从 $q$ 节点到 $p$ 节点的所有路径，并且对每条路径，求得该路径上的所有偏导数之乘积，然后将所有路径的 “乘积” 累加起来才能得到 $\frac{\partial p}{\partial q}$ 的值。</p>
<p>大家也许已经注意到，这样做是十分冗余的， <strong>因为很多路径被重复访问</strong>了。比如上图中，a-c-e和b-c-e就都走了路径c-e。对于权值动则数万的深度模型中的神经网络，这样的冗余所导致的计算量是相当大的。</p>
<p>同样是 <strong>利用链式法则，BP算法则机智地避开了这种冗余，它对于每一个路径只访问一次就能求顶点对所有下层节点的偏导值。正如反向传播(BP)算法的名字说的那样，BP算法是反向(自上往下)来寻找路径的</strong>。</p>
<p>从最上层的节点e开始，初始值为1，以层为单位进行处理。对于e的下一层的所有子节点，将1乘以e到某个节点路径上的偏导值，并将结果“堆放”在该子节点中。等e所在的层按照这样传播完毕后，第二层的每一个节点都“堆放”些值，然后我们针对每个节点，把它里面所有 <strong>“堆放”</strong> 的值求和，就得到了顶点e对该节点的偏导。然后将这些第二层的节点各自作为起始顶点，初始值设为顶点e对它们的偏导值，以”层”为单位重复上述传播过程，即可求出顶点e对每一层节点的偏导数。</p>
<p>以上图为例，节点c接受e发送的1<em>2并堆放起来，节点d接受e发送的1</em>3并堆放起来，至此第二层完毕，求出各节点总堆放量并继续向下一层发送。节点c向a发送2<em>1并对堆放起来，节点c向b发送2</em>1并堆放起来，节点d向b发送3<em>1并堆放起来，至此第三层完毕，节点a堆放起来的量为2，节点b堆放起来的量为2</em>1+3*1=5, 即顶点e对b的偏导数为5.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-11-06-deepfeedforwardnn/" data-id="ck4ifp1lz001x2wjeg2gohy4j" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-10-25-SVD-decomponent" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-10-25-SVD-decomponent/" class="article-date">
  <time datetime="2019-12-23T10:45:59.367Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-10-25-SVD-decomponent/">深度学习基础：SVD奇异值分解及其意义【转】</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>英文原文:<a href="http://blog.csdn.net/redline2005/article/details/24099377" target="_blank" rel="noopener">英文原文</a><br>中文转自:<a href="http://blog.sciencenet.cn/blog-696950-699432.html" target="_blank" rel="noopener">中文原文</a></p>
<h2 id="一-简介"><a href="#一-简介" class="headerlink" title="一 简介"></a>一 简介</h2><p>SVD实际上是数学专业内容，但它现在已经渗入到不同的领域中。SVD的过程不是很好理解，因为它不够直观，但它对矩阵分解的效果却非常好。比如，Netflix（一个提供在线电影租赁的公司）曾经就悬赏100万美金，如果谁能提高它的电影推荐系统评分预测准确率提高10%的话。令人惊讶的是，这个目标充满了挑战，来自世界各地的团队运用了各种不同的技术。最终的获胜队伍”BellKor’s Pragmatic Chaos”采用的核心算法就是基于SVD。<br>SVD提供了一种非常便捷的矩阵分解方式，能够发现数据中十分有意思的潜在模式。在这篇文章中，我们将会提供对SVD几何上的理解和一些简单的应用实例。</p>
<h3 id="1-1-线性变换的几何意义"><a href="#1-1-线性变换的几何意义" class="headerlink" title="1.1 线性变换的几何意义"></a>1.1 线性变换的几何意义</h3><p>  <strong>奇异值分解应该就是把一个线性变换分解成两个线性变换，一个线性变换代表旋转，另一个代表拉伸。</strong></p>
<p> 让我们来看一些简单的线性变换例子，以 2 X 2 的线性变换矩阵为例，首先来看一个较为特殊的，对角矩阵：</p>
<p> $$<br> M=<br> \begin{bmatrix}<br>  3\quad 0\<br>  0\quad 1 \<br> \end{bmatrix}</p>
<p> $$</p>
<p> 从几何上讲，M 是将二维平面上的点(x,y)经过线性变换到另外一个点的变换矩阵，如下图所示</p>
<p> $$<br>   \begin{bmatrix}<br>    3\quad 0 \<br>    0\quad 1\<br>   \end{bmatrix}<br>   \begin{bmatrix}<br>    x\<br>    y\<br>   \end{bmatrix} =<br>   \begin{bmatrix}<br>   3x\<br>   y\<br>   \end{bmatrix}<br> $$</p>
<p>变换的效果如下图所示，变换后的平面仅仅是沿 X 水平方面进行了拉伸3倍，垂直方向是并没有发生变化。</p>
<p><img src="/images/blog/svd1.jpg" alt="水平变换效果"></p>
<p>现在看下矩阵：</p>
<p>$$<br>M=<br>\begin{bmatrix}<br> 2\quad 1\<br> 1\quad 2 \<br>\end{bmatrix}</p>
<p>$$</p>
<p>这个矩阵产生的变换效果如下图所示:</p>
<p><img src="/images/blog/svd2.jpg" alt="水平变换效果"></p>
<p>  这种变换效果看起来非常的奇怪，在实际环境下很难描述出来变换的规律 ( 这里应该是指无法清晰辨识出旋转的角度，拉伸的倍数之类的信息)。还是基于上面的对称矩阵，假设我们把左边的平面旋转45度角，然后再进行矩阵M 的线性变换，效果如下图所示：</p>
<p>  <img src="/images/blog/svd3.jpg" alt="水平变换效果"></p>
<p>看起来是不是有点熟悉？ 对的，经过 M 线性变换后，跟前面的对角矩阵的功能是相同的，都是将网格沿着一个方向拉伸了3倍。<br>这里的 M 是一个特例，因为它是对称的。非特殊的就是我们在实际应用中经常遇见一些 非对称的，非方阵的矩阵。如上图所示，如果我们有一个 2 X 2 的对称矩阵M 的话，我们先将网格平面旋转一定的角度，M 的变换效果就是在两个维度上进行拉伸变换了。</p>
<p>用更加数学的方式进行表示的话，给定一个对称矩阵 M ，我们可以找到一些相互正交 $V_i$ ，满足 $MV_i$ 就是沿着 $V_i$ 方向的拉伸变换，公式如下：</p>
<p>$$<br>  Mv_i=\lambda _iv_i<br>$$</p>
<p>这里的 $\lambda _i$是拉伸尺度(scalar)。从几何上看，M 对向量 $V_i$ 进行了拉伸，映射变换。$V_i$ 称作矩阵 M 的特征向量(eigenvector)，$\lambda _i$ 称作为矩阵M 特征值(eigenvalue)。这里有一个非常重要的定理，对称矩阵M 的特征向量是相互正交的。</p>
<p>如果我们用这些特征向量对网格平面进行线性变换的话，再通过 M 矩阵对网格平面进行线性换的效果跟对M 矩阵的特征向量进行线性变换的效果是一样的。<br>对于更为普通的矩阵而言，我们该怎么做才能让一个原来就是相互垂直的网格平面(orthogonal grid), 线性变换成另外一个网格平面同样垂直呢？PS：这里的垂直如图所示，就是两根交错的线条是垂直的。</p>
<p>$$<br>M=<br>\begin{bmatrix}<br> 1\quad 1\<br> 0\quad 1 \<br>\end{bmatrix}</p>
<p>$$</p>
<p>经过上述矩阵变换以后的效果如图:</p>
<p>  <img src="/images/blog/svd4.jpg" alt="水平变换效果"></p>
<p>  从图中可以看出，并没有达到我们想要的效果。我们把网格平面旋转 30 度角的话，然后再进行同样的线性变换以后的效果，如下图所示</p>
<p>  <img src="/images/blog/svd5.jpg" alt="水平变换效果"></p>
<p>  让我们来看下网格平面旋转60度角的时候的效果。</p>
<p>  <img src="/images/blog/svd6.jpg" alt="水平变换效果"></p>
<p>  嗯嗯，这个看起来挺不错的样子。如果在精确一点的话，应该把网格平面旋转 58.28 度才能达到理想的效果。</p>
<p>  <img src="/images/blog/svd7.jpg" alt="水平变换效果"></p>
<h2 id="二-几何意义"><a href="#二-几何意义" class="headerlink" title="二 几何意义"></a>二 几何意义</h2><p>该部分是从几何层面上去理解二维的SVD：对于任意的 2 x 2 矩阵，通过SVD可以将一个相互垂直的网格(orthogonal grid)变换到另外一个相互垂直的网格。<br>我们可以通过向量的方式来描述这个事实: 首先，选择两个相互正交的单位向量 $v_1$和 $v_2$, 向量 $Mv_1$ 和 $Mv_2$ 正交。</p>
<p>  <img src="/images/blog/svd8.jpg" alt="水平变换效果"></p>
<p>$u_1$ 和 $u_2$ 分别表示 $Mv_1$ 和 $Mv_2$ 的单位向量，$σ_1 * u_1 =  Mv_1$ 和 $σ_2 * u_2 =  Mv_2$ 。$σ_1$ 和 $σ_2$分别表示这不同方向向量上的模，也称作为矩阵M 的奇异值。</p>
<p>  <img src="/images/blog/svd9.jpg" alt="水平变换效果"></p>
<p>这样我们就有了如下关系式：</p>
<p>$$<br>Mv_1 = σ_1u_1 \<br>Mv_2 = σ_2u_2<br>$$</p>
<p>我们现在可以简单描述下经过 M 线性变换后的向量 x 的表达形式。由于向量 $v_1$ 和 $v_2$ 是正交的单位向量，我们可以得到如下式子</p>
<p>$$<br>  x = (v_1x)v_1 + (v_2x)v_2<br>$$</p>
<p>这就意味着：</p>
<p>  $$<br>    Mx = (v_1x)Mv_1 + (v_2x)Mv_2    \<br>     Mx = (v_1x) σ_1u_1 + (v_2x) σ_2u_2<br>  $$</p>
<p>向量内积可以用向量的转置来表示，如下所示:</p>
<p>$$<br>   V. x= V^Tx<br>$$</p>
<p>最终的式子为:</p>
<p>$$<br>Mx = u_1σ_1 v_1^Tx + u_2σ_2 v_2^Tx   \<br>M =u_1σ_1 v_1^T + u_2σ_2 v_2^T<br>$$</p>
<p>上述的式子经常表示成</p>
<p>$$<br>  M = U\sum V^T<br>$$</p>
<p>u 矩阵的列向量分别是 $u_1,u_2，\sum $是一个对角矩阵，对角元素分别是对应的 $σ_1$ 和 $σ_2$ ，V矩阵的列向量分别是 $v_1,v_2$ 。上角标T 表示矩阵 V 的转置。</p>
<p>这就表明任意的矩阵 M 是可以分解成三个矩阵。V表示了原始域的标准正交基，u 表示经过M 变换后的co-domain的标准正交基，Σ表示了V 中的向量与u中相对应向量之间的关系。(V describes an orthonormal basis in the domain, and U describes an orthonormal basis in the co-domain, and Σ describes how much the vectors in V are stretched to give the vectors in U.)</p>
<h2 id="三-奇异值分解的物理意义"><a href="#三-奇异值分解的物理意义" class="headerlink" title="三 奇异值分解的物理意义"></a>三 奇异值分解的物理意义</h2><p>  此部分转载自知乎 <a href="https://www.zhihu.com/question/22237507/answer/28007137" target="_blank" rel="noopener">奇异值分解物理意义，郑宁的回答</a></p>
<p>  矩阵的奇异值是一个数学意义上的概念，一般是由奇异值分解（Singular Value Decomposition，简称SVD分解）得到。如果要问奇异值表示什么物理意义，那么就必须考虑在不同的实际工程应用中奇异值所对应的含义。下面先尽量避开严格的数学符号推导，直观的从一张图片出发，让我们来看看奇异值代表什么意义。</p>
<p>这是女神上野树里（Ueno Juri）的一张照片，像素为高度450*宽度333</p>
<p>  <img src="/images/blog/svd20.jpg" alt=""></p>
<p>  我们都知道，图片实际上对应着一个矩阵，矩阵的大小就是像素大小，比如这张图对应的矩阵阶数就是450*333，矩阵上每个元素的数值对应着像素值。我们记这个像素矩阵为 $A$ 。</p>
<p>  现在我们对矩阵 $A$ 进行奇异值分解。直观上，奇异值分解将矩阵分解成若干个秩一矩阵之和，用公式表示就是：</p>
<p>  $$<br>    A =\sigma_1\mu_1v_1^T+\sigma_2\mu_2v_2^T+…+\sigma_r\mu_rv_r^T<br>  $$</p>
<p>  其中等式右边每一项前的系数 $\sigma$就是奇异值，u和v分别表示列向量，秩一矩阵的意思是矩阵秩为1。注意到每一项 $\mu v$ 都是秩为1的矩阵。我们假定奇异值满足:</p>
<p>  $$<br>    \sigma_1\ge\sigma_2\ge….\sigma_r\ge0<br>  $$</p>
<p>（奇异值大于0是个重要的性质，但这里先别在意），如果不满足的话重新排列顺序即可，这无非是编号顺序的问题。</p>
<p>既然奇异值有从大到小排列的顺序，我们自然要问，如果只保留大的奇异值，舍去较小的奇异值，这样(1)式里的等式自然不再成立，那会得到怎样的矩阵——也就是图像？</p>
<p>令 $A_1=\sigma_1 u_1v_1^{\rm T}$ ，这只保留(1)中等式右边第一项，然后作图</p>
<p>  <img src="/images/blog/svd21.jpg" alt=""></p>
<p>结果就是完全看不清是啥……我们试着多增加几项进来:</p>
<p>$$<br>  A_5 =\sigma_1\mu_1v_1^T+\sigma_2\mu_2v_2^T+…+\sigma_5\mu_5v_5^T<br>$$</p>
<p>再作图</p>
<p><img src="/images/blog/svd22.jpg" alt=""></p>
<p>隐约可以辨别这是短发伽椰子的脸……但还是很模糊，毕竟我们只取了5个奇异值而已。下面我们取20个奇异值试试，也就是(1)式等式右边取前20项构成 $A_{20}$</p>
<p>虽然还有些马赛克般的模糊，但我们总算能辨别出这是Juri酱的脸。当我们取到(1)式等式右边前50项时：</p>
<p><img src="/images/blog/svd24.jpg" alt=""></p>
<p>我们得到和原图差别不大的图像。也就是说当k从1不断增大时，A_k不断的逼近A。让我们回到公式</p>
<p>$$<br>     A =\sigma_1\mu_1v_1^T+\sigma_2\mu_2v_2^T+…+\sigma_r\mu_rv_r^T<br>$$</p>
<p>矩阵表示一个450<em>333的矩阵，需要保存个元素的值。等式右边和分别是450</em>1和333*1的向量，每一项有个元素。如果我们要存储很多高清的图片，而又受限于存储空间的限制，在尽可能保证图像可被识别的精度的前提下，我们可以保留奇异值较大的若干项，舍去奇异值较小的项即可。例如在上面的例子中，如果我们只保留奇异值分解的前50项，则需要存储的元素为，和存储原始矩阵相比，存储量仅为后者的26%。</p>
<p><strong>奇异值往往对应着矩阵中隐含的重要信息，且重要性和奇异值大小正相关。每个矩阵A都可以表示为一系列秩为1的“小矩阵”之和，而奇异值则衡量了这些“小矩阵”对于A的权重。</strong></p>
<p>在图像处理领域，奇异值不仅可以应用在数据压缩上，还可以对图像去噪。如果一副图像包含噪声，我们有理由相信那些较小的奇异值就是由于噪声引起的。当我们强行令这些较小的奇异值为0时，就可以去除图片中的噪声。如下是一张25*15的图像（本例来源于[1]）</p>
<p><img src="/images/blog/svd25.jpg" alt=""></p>
<p>但往往我们只能得到如下带有噪声的图像（和无噪声图像相比，下图的部分白格子中带有灰色）：</p>
<p><img src="/images/blog/svd26.jpg" alt=""></p>
<p>通过奇异值分解，我们发现矩阵的奇异值从大到小分别为：14.15，4.67，3.00，0.21，……，0.05。除了前3个奇异值较大以外，其余奇异值相比之下都很小。强行令这些小奇异值为0，然后只用前3个奇异值构造新的矩阵，得到</p>
<p><img src="/images/blog/svd27.jpg" alt=""></p>
<p>可以明显看出噪声减少了（白格子上灰白相间的图案减少了）。</p>
<p>奇异值分解还广泛的用于主成分分析（Principle Component Analysis，简称PCA）和推荐系统（如Netflex的电影推荐系统）等。在这些应用领域，奇异值也有相应的意义</p>
<h2 id="四-如何获得奇异值分解"><a href="#四-如何获得奇异值分解" class="headerlink" title="四 如何获得奇异值分解"></a>四 如何获得奇异值分解</h2><p>事实上我们可以找到任何矩阵的奇异值分解，那么我们是如何做到的呢？假设在原始域中有一个单位圆，如下图所示。经过 M 矩阵变换以后在co-domain中单位圆会变成一个椭圆，它的长轴(Mv1)和短轴(Mv2)分别对应转换后的两个标准正交向量，也是在椭圆范围内最长和最短的两个向量。</p>
<p>  <img src="/images/blog/svd10.jpg" alt="水平变换效果"></p>
<p>换句话说，定义在单位圆上的函数|Mx|分别在 $v_1$ 和 $v_2$ 方向上取得最大和最小值。这样我们就把寻找矩阵的奇异值分解过程缩小到了优化函数|Mx|上了。结果发现（具体的推到过程这里就不详细介绍了）这个函数取得最优值的向量分别是矩阵 MT M 的特征向量。由于MTM是对称矩阵，因此不同特征值对应的特征向量都是互相正交的，我们用 $v_i$ 表示MTM的所有特征向量。奇异值 $σ_i = |Mv_i| $， 向量 $u_i$ 为 $Mv_i$ 方向上的单位向量。但为什么 $u_i$ 也是正交的呢？</p>
<p>推倒如下：</p>
<p>$σ_i$ 和 $σ_j$ 分别是不同两个奇异值</p>
<p>$$<br>Mv_i = σ_iu_i  \<br>Mv_j = σ_ju_j.<br>$$</p>
<p>我们先看下MviMvj，并假设它们分别对应的奇异值都不为零。一方面这个表达的值为0，推到如下</p>
<p>$$<br>Mv_i Mv_j = v_i^TM^T Mv_j = v_i M^TMv_j = λ_jv_i v_j = 0<br>$$</p>
<p>另一方面，我们有</p>
<p>$$<br>Mv_i Mv_j = σ_iσ_j u_i u_j = 0<br>$$</p>
<p>因此，$u_i$ 和 $u_j$ 是正交的。但实际上，这并非是求解奇异值的方法，效率会非常低。这里也主要不是讨论如何求解奇异值，为了演示方便，采用的都是二阶矩阵。</p>
<h2 id="五-应用实例"><a href="#五-应用实例" class="headerlink" title="五 应用实例"></a>五 应用实例</h2><h3 id="5-1-应用实例一"><a href="#5-1-应用实例一" class="headerlink" title="5.1 应用实例一"></a>5.1 应用实例一</h3><p>$$<br>M =<br>  \begin{bmatrix}<br>   1\quad 1 \<br>   2\quad 2 \<br>  \end{bmatrix}<br>$$</p>
<p>经过这个矩阵变换后的效果如下图所示</p>
<p><img src="/images/blog/svd11.jpg" alt="水平变换效果"></p>
<p>在这个例子中，第二个奇异值为 0，因此经过变换后只有一个方向上有表达</p>
<p>$$<br>  M =u_1σ_1 v_1^T<br>$$</p>
<p>换句话说，如果某些奇异值非常小的话，其相对应的几项就可以不同出现在矩阵 M 的分解式中。因此，我们可以看到矩阵 M 的秩的大小等于非零奇异值的个数。</p>
<h3 id="5-2-应用实例二"><a href="#5-2-应用实例二" class="headerlink" title="5.2  应用实例二"></a>5.2  应用实例二</h3><p> 我们来看一个奇异值分解在数据表达上的应用。假设我们有如下的一张 15 x 25 的图像数据。</p>
<p><img src="/images/blog/svd12.jpg" alt="水平变换效果"></p>
<p>如图所示，该图像主要由下面三部分构成。</p>
<p><img src="/images/blog/svd13.jpg" alt="水平变换效果"></p>
<p>我们将图像表示成 15 x 25 的矩阵，矩阵的元素对应着图像的不同像素，如果像素是白色的话，就取 1，黑色的就取 0. 我们得到了一个具有375个元素的矩阵，如下图所示</p>
<p><img src="/images/blog/svd14.jpg" alt="水平变换效果"></p>
<p>如果我们对矩阵M进行奇异值分解以后，得到奇异值分别是</p>
<p>$$<br>σ_1 = 14.72 \<br>σ_2 = 5.22  \<br>σ_3 = 3.31 \<br>$$</p>
<p>矩阵M就可以表示成</p>
<p>$$<br>M=u_1σ_1 v_1^T + u_2σ_2 v_2^T + u_3σ_3 v_3^T<br>$$</p>
<p>$v_i$ 具有15个元素，$u_i$ 具有25个元素，$σ_i$ 对应不同的奇异值。如上图所示，我们就可以用123个元素来表示具有375个元素的图像数据了。</p>
<h3 id="5-3-应用实例三：减噪-noise-reduction"><a href="#5-3-应用实例三：减噪-noise-reduction" class="headerlink" title="5.3 应用实例三：减噪(noise reduction)"></a>5.3 应用实例三：减噪(noise reduction)</h3><p> 前面的例子的奇异值都不为零，或者都还算比较大，下面我们来探索一下拥有零或者非常小的奇异值的情况。通常来讲，大的奇异值对应的部分会包含更多的信息。比如，我们有一张扫描的，带有噪声的图像，如下图所示</p>
<p> <img src="/images/blog/svd15.jpg" alt="水平变换效果"></p>
<p> 我们采用跟实例二相同的处理方式处理该扫描图像。得到图像矩阵的奇异值：</p>
<p> $$<br>σ_1 = 14.15   \<br>σ_2 = 4.67     \<br>σ_3 = 3.00   \<br>σ_4 = 0.21   \<br>σ_5 = 0.19  \<br>…<br>σ_15 = 0.05 \<br> $$</p>
<p>很明显，前面三个奇异值远远比后面的奇异值要大，这样矩阵 M 的分解方式就可以如下：</p>
<p>$$<br>  M \approx  u_1σ_1 v_1^T + u_2σ_2 v_2^T + u_3σ_3 v_3^T<br>$$</p>
<p>经过奇异值分解后，我们得到了一张降噪后的图像。</p>
<p><img src="/images/blog/svd16.jpg" alt="水平变换效果"></p>
<h3 id="5-4-应用实例四：数据分析-data-analysis"><a href="#5-4-应用实例四：数据分析-data-analysis" class="headerlink" title="5.4 应用实例四：数据分析(data analysis)"></a>5.4 应用实例四：数据分析(data analysis)</h3><p>我们搜集的数据中总是存在噪声：无论采用的设备多精密，方法有多好，总是会存在一些误差的。如果你们还记得上文提到的，大的奇异值对应了矩阵中的主要信息的话，运用SVD进行数据分析，提取其中的主要部分的话，还是相当合理的。<br>作为例子，假如我们搜集的数据如下所示：</p>
<p><img src="/images/blog/svd17.jpg" alt="水平变换效果"></p>
<p>我们将数据用矩阵的形式表示：</p>
<p><img src="/images/blog/svd18.jpg" alt="水平变换效果"></p>
<p>经过奇异值分解后，得到</p>
<p>$$<br>σ_1 = 6.04  \<br>σ_2 = 0.22 \<br>$$</p>
<p>由于第一个奇异值远比第二个要大，数据中有包含一些噪声，第二个奇异值在原始矩阵分解相对应的部分可以忽略。经过SVD分解后，保留了主要样本点如图所示</p>
<p><img src="/images/blog/svd19.jpg" alt="水平变换效果"></p>
<p>就保留主要样本数据来看，该过程跟PCA( principal component analysis)技术有一些联系，PCA也使用了SVD去检测数据间依赖和冗余信息.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-10-25-SVD-decomponent/" data-id="ck4ifp1ly001v2wje52leaduv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-10-19-optimization-deep-models" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-10-19-optimization-deep-models/" class="article-date">
  <time datetime="2019-12-23T10:45:59.365Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-10-19-optimization-deep-models/">深度学习：训练模型的优化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一-概述"><a href="#一-概述" class="headerlink" title="一 概述"></a>一 概述</h2><p>本文主要集中探讨优化方法中的一种特例：找到使得神经网络损失大幅度减小的参数 $\theta$ ,这一般会包含了在整个训练集上的性能评估方法和一些额外的正则项。<br>本文所描述的机器学习算法的优化与纯粹的优化略有不同。接下来我们将阐述使得神经网络变得尤其复杂的挑战。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-10-19-optimization-deep-models/" data-id="ck4ifp1lx001r2wje35bdhcox" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-10-09-regularization-deeplearning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-10-09-regularization-deeplearning/" class="article-date">
  <time datetime="2019-12-23T10:45:59.352Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-10-09-regularization-deeplearning/">深度学习：正则化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="7-1-概念"><a href="#7-1-概念" class="headerlink" title="7.1 概念"></a>7.1 概念</h2><p>  深度学习中用以减小测试误差，但可能会增加训练误差的策略称为正则化。</p>
<p>  <strong>限制</strong>：有些正则化策略是<strong>机器学习模型</strong>上添加限制。有些在<strong>模型参数</strong>上，有些在<strong>目标函数</strong>上添加额外项。这些限制或惩罚部分被设计来对特定先验知识编码的，其余的则是为了提高模型泛化能力。</p>
<p>  深度学习中大部分正则化策略都是基于估计正则化，而估计正则化则是通过增加偏置来减少方差。 一个估计的正则化的目标是在大幅度减小方差的同时，尽可能小的带来偏置的增加。我们在讨论泛化和过拟合问题时会遇到以下三种情形:</p>
<p>  <img src="/images/blog/regular1.png" alt="拟合情况"></p>
  <p align="Center">图7.1</p>

<ul>
<li><p><strong>欠拟合</strong>:实际的正例没有完全被包含在模型预测域。</p>
</li>
<li><p><strong>绝佳</strong>：完全匹配了数据生成过程.</p>
</li>
<li><p><strong>过拟合</strong>：模型的预测域包含了全部的正例，同时也包含了负例。</p>
<p>正规化的目标就是将模型的<strong>过拟合</strong>情形改善至<strong>绝佳</strong>情形。</p>
<p>现实情况中，即便是极端复杂的模型也没法完全拟合目标函数，因为大部分情况，我们并不知道目标函数具体是如何映射的。<br>这表明设计一个模型的复杂度极高(模型大小，参数等)。而在近些年的实际实验中，我们发现比较好的模型都是正规化处理过后的大模型。</p>
</li>
</ul>
<h2 id="7-2-参数规范惩罚"><a href="#7-2-参数规范惩罚" class="headerlink" title="7.2 参数规范惩罚"></a>7.2 参数规范惩罚</h2><p> 目前许多正规化方法，如神经网络、线性回归、logistic回归通过在目标函数$J$上加一个参数规范惩罚项 $\Omega(\theta)$ 公式如下:</p>
<p>$$<br>    \bar{J}(\theta;X,y) = J(\theta;X,y)+\alpha\Omega(\theta)\\tag {7.1}</p>
<p> 其中 \alpha\epsilon [0,\infty)<br>$$</p>
<p>其中，更大的 $\alpha$ 对应更强的正规化处理。</p>
<p> 在神经网络中，使用参数规范惩罚，只是对每一层映射转换的权重，不对偏置使用。这是因为权重决定了两个变量如何交互，而偏置只作用于单一变量。同时正规化偏置容易引入欠拟合。</p>
<p><strong>预定义</strong></p>
<ul>
<li><p>向量$w$代表所有需要被规范惩罚的权重</p>
</li>
<li><p>向量 $\theta$代表所有参数，包括$w$和其他非正规化的参数</p>
<p>尽管每一层使用独立的 $\alpha$参数的惩罚机制效果可能会更好，但是由于计算量太大。实际中所有层使用相同的权重衰减。</p>
</li>
</ul>
<p><strong>如何理解正则化</strong></p>
<p>从数学角度来看，成本函数增加了一个正则项 $\Omega(\theta)$ 后，成本函数不再唯一地与预测值与真实值的差距决定，还和参数 $\theta$ 的大小有关。有了这个限制之后，要实现成本函数最小的目的，$\theta$ 就不能随便取值了，比如某个比较大的 $\theta$ 值可能会让预测值与真实值的差距 $\left( h_\theta(x^{(i)}) - y^{(i)} \right)^2$ 值很小，但会导致 $\theta_j^2$ 很大，最终的结果是成本函数太大。这样，通过调节参数 $\lambda$ 就可以控制正则项的权重。从而避免算法过拟合</p>
<h3 id="7-2-1-L-2-参数正规化"><a href="#7-2-1-L-2-参数正规化" class="headerlink" title="7.2.1 $L^2$ 参数正规化"></a>7.2.1 $L^2$ 参数正规化</h3><p>最简单最常见的正规惩罚莫过于$L^2$，有时候称为<em>权重衰减</em>，同时也称为<em>岭回归</em>或者<em>吉洪诺夫正规</em>。它是直接在目标函数后面添加一个正规项 $\Omega(\theta)=\frac{1}{2}|w|^2_2$</p>
<p>L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项 $|W|_2$最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。</p>
<p>回头看式子 $(7.1)$，假设没有偏置参数，因此 $\theta$参数就是$w$,模型目标函数如下:<br>   $$<br>    \bar J(w;X,y) =\frac{\alpha}{2}w^Tw+J(w;X,y) \tag{7.2}<br>   $$</p>
<p>对应的参数梯度如下:</p>
<p>   $$<br>     \bigtriangledown\bar J_w(w;X,y)=\alpha w+\bigtriangledown_wJ(w;X,y)<br>   $$</p>
<p>使用梯度更新权重时:</p>
<p>   $$<br>    w\leftarrow w-\epsilon(\alpha w+\bigtriangledown_wJ(w;X,y))<br>   $$</p>
<p>   重写为:</p>
<p>   $$<br>    w\leftarrow (1-\epsilon\alpha)w -\epsilon\bigtriangledown_wJ(w;X,y))<br>   $$</p>
<p>可以看到新增权重衰减项最终反映出，它通过对每一步的权重向量乘以一个常数因子修改了学习规则。由于 $\epsilon$ ，$\alpha$都是正值，所以它实际是减小了$w$。这就是它被称为<strong>权重衰减</strong>的原因。</p>
<h4 id="7-2-1-1-L-2-如何实现参数调整"><a href="#7-2-1-1-L-2-如何实现参数调整" class="headerlink" title="7.2.1.1 $L^2$如何实现参数调整"></a>7.2.1.1 $L^2$如何实现参数调整</h4><p>  假设没有进行正则化处理的模型的损失函数在权重 $w$ 更新为 $w^ <em>$ 时最小。我们通过在 $w^</em> $ 附近进行二次近似来简化分析（前提是损失函数是二次及以上）。此时对损失函数的近似为:</p>
<p>$$<br>   \widetilde J(\theta)=J(w^<em>)+\frac{1}{2}(w-w^</em>)^TH(w-w^<em>) \<br>   其中H为w在w^</em>处的Hessian矩阵<br>$$</p>
<p>当梯度</p>
<p>$$<br>   \bigtriangledown_w\widetilde J(w)=H(w-w^*) \tag 7<br>$$</p>
<p>为0时， $\widetilde J$ 最小。将式子(7)，增加权重衰减项并修改为：</p>
<p>$$<br>   \alpha \widetilde w+H(\widetilde w-w^<em>)=0 \tag 8\<br>   (H+\alpha I)\widetilde w= Hw</em> \<br>   \widetilde w = (H+\alpha I)^{-1}Hw*<br>$$</p>
<p>如果 $\alpha$ 趋近于0，正则化的解 $\widetilde w$趋近于 $w*$。但是如果 $\alpha$增加，由于 $H$ 是实数并且是对称的，我们将上式解构为如下（其中 $\Lambda$ 为对角矩阵，$Q$ 为特征向量的正交基向量使得 $H=Q\Lambda Q^T$）：</p>
<p>$$<br>  \widetilde w =(Q\Lambda Q^T +\alpha I)^{-1}Q\Lambda Q^Tw<em>\<br>  =[Q(\Lambda +\alpha I)Q^T]^{-1}Q\Lambda Q^Tw*\<br>  =Q(\Lambda +\alpha I)^{-1}\Lambda Q^Tw</em><br>$$</p>
<p>我们可以看到权重衰减的效果是由 $H$ 的特征向量定义的轴上重新调整 $w*$ , $H$ 的第 $i$ 个特征向量由一个因子 $\frac{\lambda _i}{\lambda _i+\alpha}$ 重新调整。可以得知</p>
<ul>
<li><p>当 $\lambda _i\gg \alpha$ 时，正则化效果十分有限。</p>
</li>
<li><p>当 $\lambda _i\ll \alpha$ 时，将极大地改变 $w*$，几乎可以得到$w\sim 0，但是不为0$。</p>
<p><strong>如何防止过拟合</strong>:更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合刚刚好,而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。</p>
<p>过拟合的时候，拟合函数的系数往往非常大，为什么？如下图(图7.2)所示，过拟合，就是拟合函数需要顾及每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。</p>
<p><img src="/images/blog/regular2.png" alt="L2正则化示例"></p>
<p align="Center">图7.2</p>

<p>而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。</p>
</li>
</ul>
<h3 id="7-2-2-L-1-正则化处理"><a href="#7-2-2-L-1-正则化处理" class="headerlink" title="7.2.2 $L^1$正则化处理"></a>7.2.2 $L^1$正则化处理</h3><p>对模型参数$w$上的$L^1$正归化是增加一个惩罚项</p>
<p>$$<br>  \Omega(\theta) = |w|_1=\sum_i|w_i|<br>$$</p>
<p>完整公式如下：</p>
<p>$$<br>     \bar J(w;X,y) =\alpha|w|_1+J(w;X,y)<br>$$</p>
<p> 对上式求梯度得到：</p>
<p> $$<br> \bigtriangledown _w \bar J(w;X,y) = \alpha sign(w)+\bigtriangledown _w J(X,y;w)<br> $$</p>
<p> 可以看到，$L^1$正规化对梯度的影响不再与每个$w_i$线性相关，而是一个常量因子。符号只与$w$相关，当w为正时，更新后的w变小。当w为负时，更新后的w变大（因此它的效果就是让w往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合。 当w为0时怎么办？当w等于0时，|W|是不可导的，所以我们只能按照原始的未经正则化的方法去更新w，这就相当于去掉 $\alpha sign(w)$ 这一项，所以我们可以规定$sgn(0)=0$，这样就把w=0的情况也统一进来了）。这种形式的梯度使得没有必要继续求 $J(X,u;w)$ 的二次近似。</p>
<p> 简单的线性模型可以使用对应的<em>Taylor</em>级数来表述其二次损失函数。我们可以想象一个更复杂模型的损失函数的一个截断的泰勒级数。此时的梯度为:</p>
<p>$$<br>\bigtriangledown _w\widetilde J(w)=H(w-w*)<br>$$</p>
<p>此时 $H$ 依然为矩阵 $J$ 在 $w=w^<em>$ 处的</em>Hessian<em>矩阵。由于 $L^1$ 惩罚在完整的Hessian举证并没有清晰的代数表达式，我们可以作进一步的简化假设</em>Hessian*矩阵是对角矩阵（这个假设的前提是所有输入特征被移除了相关性）, $H=diag([H_{1,1},… H_{n,n}])$,其中每个 $H_{i,i}\gt 0$ 。</p>
<p>此时使用 $L^1$ 正则化的目标函数的二次近似可以分解为如下参数:</p>
<p>$$<br>\widetilde J(w;X,y) = J(w<em>;X,y)+\sum_i[\frac{1}{2}H_{i,i}(w_i-w^</em>_i)^2+\alpha |w_i|]<br>$$</p>
<p>最小化上面的损失函数(对每个维度 $i$ )有一个如下形式的解析解:</p>
<p>$$<br> w_i =sign(w_i^<em>)max{|w^</em><em>i|-\frac{\alpha}{H</em>{i,i}},0}<br>$$</p>
<p>考虑到条件是，对每个 $i$ 都有 $w_i\gt0$,此时可能的结果为(下列公式中 $w_i$应该都是 $w^*_i$):</p>
<ul>
<li><p>$w_i\le\frac{\alpha}{H_{i,i}}$ 时， $w_i=0$ ,因为 $\widetilde J(w;X,y)$ 中的 $J(w;X,y)$ 在方向 $i$ 上完全被 $L^1$ 正则项覆盖。</p>
</li>
<li><p>$w_i\gt\frac{\alpha}{H_{i,i}}$ 时，正则项没有将 $w_i$ 的最优置于0，而只是在该方向上移动了距离 $\frac{\alpha}{H_{i,i}}$</p>
</li>
</ul>
<p><strong>用途:</strong> 与 $L^2$ 正则化相比$L^1$ 会导致参数稀疏，参数稀疏指的是一些参数被优化到0。 $L^1$ 正则化产生的稀疏属性可被用作特征选取，参数被惩罚为0的特征可以被丢弃。</p>
<h2 id="7-3-规范惩罚用作约束优化"><a href="#7-3-规范惩罚用作约束优化" class="headerlink" title="7.3 规范惩罚用作约束优化"></a>7.3 规范惩罚用作约束优化</h2><p>考虑一个使用了参数规范惩罚正则化的损失函数</p>
<p>$$<br>  \bar J(\theta;X,y) = J(\theta;X,y)+\alpha \Omega(\theta)<br>$$</p>
<p>我们可以通过构建一个拉格朗日函数求在约束条件下目标函数的最小值，构建函数即在原始目标函数上添加一些惩罚项。假若我们想要约束条件 $\Omega(\theta)$ 小于一个常量k,可以构建如下拉格朗日函数:</p>
<p>$$<br>  L(\theta,\alpha;X,y) =J(\theta;X,y)+\alpha(\Omega(\theta)-k)<br>$$</p>
<p>此问题的解为</p>
<p>$$<br>  \theta^* =arg \quad min_{\theta}\quad max_{\alpha,alpha\ge 0}L(\theta,\alpha)<br>$$</p>
<p>可以通过修改 $\theta$ 和 $\alpha$ 的来解此问题，一些使用梯度，一些使用解析解(梯度为0)，但是需保证有</p>
<ul>
<li>$\Omega (\theta)\gt k$时 $\alpha$ 增加</li>
<li>$\Omega(\theta)&lt;k$时 $\alpha$ 减小</li>
</ul>
<p>所有的正 $\alpha$ 都会缩小 $\Omega(\theta)$ ，而最优的 $\alpha ^* $ 会缩小 $\Omega(\theta)$ 但是不会使得 $\Omega(\theta)$ 过于小于k。为了解受限条件的效果，我们可以固定 $\alpha ^* $，将问题转化为 $\theta$ 的函数。</p>
<p>$$<br>  \theta ^* =arg\quad min_{\theta}L(\theta,\alpha ^<em>)=arg\quad min_{\theta}J(\theta;X,y)+\alpha ^</em>\Omega(\theta)<br>$$</p>
<p>该式子与最小化 $\widetilde J$ 的正则化训练问题完全一致。可以将参数正则惩罚问题看做权重约束。通过系数 $\alpha ^* $ 的权重衰减，无法知晓约束区域，因为 $\alpha^* $ 并没有直接指明k的值。我们可以求解k,但k与 $\alpha^*$ 的关系依赖于 $J$ 的形式。</p>
<p>虽然无法精确制导约束区间大小，但是可通过调整 $\alpha$ 来控制，$\alpha$ 增加，则约束区间减小，反之则增大（参照惩罚项）。</p>
<h4 id="7-3-1-约束问题中精确约束"><a href="#7-3-1-约束问题中精确约束" class="headerlink" title="7.3.1 约束问题中精确约束"></a>7.3.1 约束问题中精确约束</h4><p>有时候我可能需要使用精确约束条件而不是惩罚项，此时需要通过修改算法如<strong><em>SGD</em></strong>在函数 $J(\theta)$ 上下降，并将 $\theta$ 投影回满足 $\Omega (\theta)&lt;k$的最邻近点。甚至如果我们知道何时的 $k$ ，而不想浪费时间继续搜索与 $k$ 相对应的 $\alpha$ ，此时将很有用。</p>
<p>另一个使用精确约束和重映射，而不是惩罚约束的原因是，惩罚机制会导致非凸优化而使得目标函数陷入局部最优，导致神经网络僵死。</p>
<p>最后，使用重新映射的精确约束可以在优化过程中增加稳定性。使用高学习率时会遇到正反馈循环问题，大权重将减小大梯度，进而大幅度更新权重。若不断更新权重，参数 $\theta$ 将从原始值更新到数值溢出。使用重新映射的精确约束可阻止反馈循环的权重无限增加。</p>
<h2 id="7-4-正则化和受限问题"><a href="#7-4-正则化和受限问题" class="headerlink" title="7.4 正则化和受限问题"></a>7.4 正则化和受限问题</h2><p> 机器学习中正则化是十分必要的，许多线性模型依赖转置矩阵 $X^TX$ 如线性回归模型，主成分分析(PCA)模型，但是若 $X^TX$ 是奇异的（行列式为0，有无穷个解），就没法实现。当数据在某一些方向上没有方差（所有的值相同）时，矩阵是奇异的。此时需要进行相对应的正则化来保证矩阵是可逆的。</p>
<p>当线性问题的相关矩阵是可逆时才有封闭解。欠定方程也可能没有封闭解。一个例子是，逻辑回归用于线性可分类问题时，如果权重 $w$ 可获得最佳分类结果，那么$2w$ 也可以，而且使用最大似然框架时，似然度更高。进行迭代优化如使用SGD(随机梯度下降)时将会导致 $w$ 不断增加，而算法不会停止（实际中会产生数值溢出）。</p>
<p>大多数正则化可以保证迭代方法收敛，比如权重衰减( $L^2$ 正则化)中似然函数梯度等于权重衰减系数时停止。</p>
<p><strong>（多元）线性回归问题的损失函数为：</strong></p>
<p>$$<br>  (Xw-y)^T(Xw-y)<br>$$</p>
<p>对应的解为:(参考附录)</p>
<p>$$<br>w = (X^T X)^{-1} X^T y<br>$$</p>
<p>（可以看到，如果 $X^TX$ 是奇异的，将无法求解）</p>
<p>添加 $L^2$ 正则项之后的损失函数变为:</p>
<p>$$<br>  (Xw-y)^T(Xw-y)+\frac{1}{2}\alpha w^Tw<br>$$</p>
<p>此时的正则化解为：</p>
<p>$$<br>w = (X^T X + \alpha I)^{-1} X^T y<br>$$</p>
<p>其中，$I$ 是 (n + 1) x (n + 1) 矩阵</p>
<p>$$<br>Z =<br>\begin{bmatrix}<br>0 \<br>&amp; 1 \<br>&amp; &amp; 1 \<br>&amp; &amp; &amp; \ddots \<br>&amp; &amp; &amp; &amp; 1<br>\end{bmatrix}<br>$$</p>
<p>正则化实际上解决了两个问题。一个是确保不发生过拟合，另外一个也解决了 $X^T X$ 的奇异矩阵问题。当 m &lt; n 时，$X^T X$ 将是一个奇异矩阵，从数学上可以证明，加上 $\alpha I$ 后，结果将是一个非奇异矩阵。</p>
<h2 id="7-5-数据增强"><a href="#7-5-数据增强" class="headerlink" title="7.5 数据增强"></a>7.5 数据增强</h2><p>理论上来说，数据越多，模型训练得越充分，模型泛化能力越强。但是现实情况是，数据量总是有限的，解决此问题的一个方法是生成一部分的模拟数据。</p>
<p>这对于分类问题最简单，它需要喂入复杂的高维度数据输入并映射到一个单一分类上。这说明，分类问题主要面临的是对于任意广度的输入其分类结果不变。我们可以简单的生成一个 $(x,y)$ 即可。但是对于很多其他问题，如密度估计问题，很难生成模拟数据，除非已经知道需要解决的密度估计问题。  </p>
<p> <strong>图像识别</strong>：数据增强用于特定领域分类问题，如图像识别很有效。但是切记，转换数据的时候不要改变图像的正确分类。比如不要将手写字识别图像中的<code>6</code> 垂直转换成了<code>9</code>，<code>b</code>水平翻转成了<code>d</code>。    </p>
<p> <strong>语音识别</strong>：语音识别问题中，网络输入数据中也会注入一些随机噪音干扰，这也是一种数据增强（现实生活中语音环境有噪音）。</p>
<p>  神经网络对噪音鲁棒性并不好，所以我们在可以有一种提升网络性能的方法，即在训练时加入随机干扰。</p>
<p>  由于数据增强的存在，我们在比较机器学习结果时应当考虑数据增强。手工设计的数据通常可以大幅度减少泛化错误。所以，在比较机器学习算法时，需要做对照试验，使用相同算法，一组使用没有应用数据增强的输入A，另一组使用应用了数据增强的B，如果A的性能很差，而B的性能很好，那么说明促使模型性能提升的不是算法而是数据。</p>
<h2 id="7-6-噪声鲁棒"><a href="#7-6-噪声鲁棒" class="headerlink" title="7.6 噪声鲁棒"></a>7.6 噪声鲁棒</h2><p> 对于使用了数据增强的模型，噪音其实等同于在权重分布上增加了惩罚机制。通常，噪音注入比简单的收缩参数(正则化)更有用，尤其是噪音作用于隐藏神经元时，dropout就是专门在方面的进展。<br> 在RNN中，权重上增加噪声被证明是一种很有效的正则策略（书中论文）。接下来分析下标准前馈神经网络中权重噪音的实际影响。<br> 在回归问题中，假设损失函数是最小平方误差，如下:</p>
<p> $$<br>   J = E_{p(x,y)}[(\bar y(x)-y)^2]<br> $$</p>
<p> 假设输入中包含随机扰动 $\epsilon_w \sim N(\epsilon ;0,\eta I)$ ，此时对应的目标函数变成:</p>
<p> $$<br>   \bar J_W=E_{p(x,y,\epsilon <em>w)}[(\bar y</em>{\epsilon_W}(x)-y)^2] \<br>   =E_{p(x,y,\epsilon_W)}[\bar y^2_{\epsilon_W}(x)-2y\bar y_{\epsilon_W}(x)+y^2]<br> $$</p>
<p> 若 $\eta$ 很小,最小化 $J$ 等同于最小化 $J$ 外加一个正则项 $\eta E_{p(x,y)}[|\bigtriangledown_W\bar y(x)|^2]$<br>这种正则项使得模型对参数的轻微扰动不再敏感，此时的最优参数不在使得损失函数最小点而是在最小点附近。</p>
<h3 id="7-6-1-在输出目标上注入噪音"><a href="#7-6-1-在输出目标上注入噪音" class="headerlink" title="7.6.1 在输出目标上注入噪音"></a>7.6.1 在输出目标上注入噪音</h3><p> 模型的错误分类将导致最大似然框架求得的 $logP(y|x)$ 并不是真正最大点。一种办法是在标签上加入噪音，例如常量 $\theta$ ，此时训练数据集x，其输出被分类到标签y的概率为 $1-\theta$ ，这种方法很容易并入到惩罚函数，而不需要引入噪声数据。这是一种平滑机制，比如标签正则模型基于有k个输出的 <em>softmax</em> ，将分类<code>0</code>,<code>1</code>替换为 $\frac{\theta}{k}$ 和 $1-\frac{k-1}{k}\theta$</p>
<h2 id="7-7"><a href="#7-7" class="headerlink" title="7.7"></a>7.7</h2><p> 多任务学习</p>
<p> 多任务学习可以看做一种从多个模型中抽象出一个汇总模型以提高泛化能力的方法。模型的某个部分的参数在多个任务间共享时，该部分将获得更好的泛化能力。</p>
<p> 下图(图7.3)展示了一个多任务学习方法的常见形式，不同的监督学习任务(对于给定输入X预测输出Y)，共享了相同的输入X，以及一些中间表述层 $h^{shared}$ (捕获参数的一些平均特征)。</p>
<p> <img src="/images/blog/regular3.png" alt=""></p>
 <p align="Center">图7.3</p>

<p> 通过提升这些共享参数的统计特性（更稳定），可以提高模型泛化能力和泛化边界。与单任务学习相比，其实是按比例增加了共享参数的输入样本。当然前提是，多个模型之间可以共享参数。</p>
<p> 以深度学习的观点来看，这种方法的先验知识是：不同模型的输入数据有些解释了数据变动的参数是在多个任务中共享的。</p>
<h2 id="7-8-提前终止"><a href="#7-8-提前终止" class="headerlink" title="7.8 提前终止"></a>7.8 提前终止</h2><p> 看一张图(图7.4)：</p>
<p> <img src="/images/blog/regular4.png" alt=""></p>
 <p align="Center">图7.4</p>

<p> 我们可以看到随着时间或迭代次数的增加，训练误差不断减少，而验证误差最后会逐渐上升，呈U型。验证误差开始上升时，已经出现了过拟合。我们应当在验证误差有段时间没有下降时停止迭代，而不是等到验证误差达到某个极小值时。此策略即提前终止，是正则化策略中最常见，最有效的方法。</p>
<p> <strong>如何确定何时终止:</strong></p>
<ul>
<li>在算法开始之前，先确定训练次数。</li>
<li>在训练过程中定期地运行验证，验证集可以比训练集数据量小。</li>
</ul>
<p><strong>优点</strong>：</p>
<ul>
<li>几乎不改变算法过程，易于使用</li>
<li>提前终止可以很容易地与其他正则化方法结合使用。</li>
</ul>
<p><strong>代价</strong>：</p>
<ul>
<li>需要不断保存最优模型参数，这是可以接收的，可以直接存放在磁盘上。</li>
<li>需要一个验证数据集，验证数据集不用于训练。</li>
</ul>
<p><strong>最大化利用所有数据</strong></p>
<p>  为了更好的利用所有数据，可以在算法提前终止后再次训练。此时有两种策略</p>
<ul>
<li><p>重新初始化模型，在所有数据集上重新训练，但只训练提前终止训练的次数。此时可以增加一些参数，因为数据更多（个人认为，其实是分两步走，第一步是用提前终止找到最优训练次数，第二次再完全训练）</p>
</li>
<li><p>保存第一次训练时的所有参数，并在所有数据上继续训练。此时无法知晓算法何时停止，但是可以观察验证数据集上的平均Loss，当其低于第一次训练的loss时停止。此方法可以避免第一次的重复计算，但是表现一般。</p>
</li>
</ul>
<p><strong>提前终止的内在机制</strong>：一些论文认为，它能将参数搜索空间限制在较小区间，进而加快模型训练。实际上在使用均方差作为损失函数和梯度下降更新参数的简单线性回归模型中，$L^2$ 正则等同于提前终止。</p>
<h2 id="7-9-参数捆绑和参数共享"><a href="#7-9-参数捆绑和参数共享" class="headerlink" title="7.9 参数捆绑和参数共享"></a>7.9 参数捆绑和参数共享</h2><p>前面的部分讲的都是在固定区域或点对参数加约束或惩罚，例如 $L^2$ 从0点开始寻找最优参数。有时候我们的先验知识需要其他表现形式，或者有时候无法确定精确值，但是知道参数之间的依赖。</p>
<p>前面讲到的参数规范惩罚是一种让参数近似另外一个参数的正则化方法，一种更常见的形式是:<strong>强制让一群参数相等</strong>，此方法称为<strong>参数共享</strong>。其优势在于，可以大幅度减少需要存储和更新的参数。该方法在卷积神经网络中尤其有效。</p>
<p>一个图像处理的例子如下图所示:</p>
<p><img src="/images/blog/regular9.png" alt="卷积图像"></p>
<p>上图左图为全连接，右图为局部连接。在上右图中，假如每个神经元（隐藏层100万个神经元）只和10×10个像素值相连，那么权值数据为1000000×100个参数，减少为原来的万分之一。而那10×10个像素值对应的10×10个参数，其实就相当于卷积操作。但其实这样的话参数仍然过多，再使用权值共享。在上面的局部连接中，每个神经元都对应100个参数，一共1000000个神经元，如果这1000000个神经元的100个参数都是相等的，那么参数数目就变为100（100万个神经元每个神经元与100个(10x10像素)参数相关，现在这100个参数一样了）了。</p>
<p>怎么理解权值共享呢？我们可以这100个参数（也就是卷积操作）看成是提取特征的方式，该方式与位置无关。这其中隐含的原理则是：图像的一部分的统计特性与其他部分是一样的。这也意味着我们在这一部分学习的特征也能用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。</p>
<p>更直观一些，当从一个大尺寸图像中随机选取一小块，比如说 8x8 作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这个 8x8 样本中学习到的特征作为探测器，应用到这个图像的任意地方中去。特别是，我们可以用从 8x8 样本中所学习到的特征跟原本的大尺寸图像作卷积，从而对这个大尺寸图像上的任一位置获得一个不同特征的激活值。</p>
<h2 id="7-10-稀疏表述"><a href="#7-10-稀疏表述" class="headerlink" title="7.10 稀疏表述"></a>7.10 稀疏表述</h2><p> 权重衰减是通过在权重参数上增加惩罚项，另一种策略是在网络神经元上施加惩罚。</p>
<p> $L^1$ 正则化带来了稀疏项，是通过使得部分参数为0，而稀疏表述则直接让其中的表述元素直接为0.举例线性回归来说明这种差别:</p>
<p> <strong>参数稀疏的表述：</strong></p>
<p> $$<br>   \begin{bmatrix}<br>   18\<br>   5\<br>   15\<br>   -9\<br>   -3<br>   \end{bmatrix}=\begin{bmatrix}<br>    4\quad0\quad0\quad-2\quad0\quad0\<br>    0\quad0\quad-1\quad0\quad3\quad0\<br>    0\quad5\quad0\quad0\quad0\quad0\<br>    1\quad0\quad0\quad-1\quad0\quad-4<br>   \end{bmatrix}</p>
<p>   \quad\begin{bmatrix}<br>    2\<br>    3\<br>    -2\<br>    -5\<br>    1\<br>    4<br>   \end{bmatrix}\<br>   y\epsilon R^m \quad\quad\quad \quad \quad A\epsilon R^{m\times n}\quad\quad\quad\quad x \epsilon R^m<br> $$</p>
<p> <strong>表述稀疏的</strong>:</p>
<p> $$<br>   \begin{bmatrix}<br>   -14\<br>   1\<br>   19\<br>   2\<br>   23<br>   \end{bmatrix}=\begin{bmatrix}<br>    3\quad-1\quad2\quad-5\quad4\quad1\<br>    4\quad2\quad-3\quad-1\quad1\quad3\<br>    -1\quad5\quad4\quad2\quad-3\quad-2\<br>    3\quad1\quad2\quad-3\quad0\quad-3\<br>    -5\quad4\quad-2\quad2\quad-5\quad-1\<br>   \end{bmatrix}</p>
<p>   \quad\begin{bmatrix}<br>    0\<br>    2\<br>    0\<br>    0\<br>    -3\<br>    0<br>   \end{bmatrix}\<br>   y\epsilon R^m \quad\quad\quad \quad \quad B\epsilon R^{m\times n}\quad\quad\quad\quad h \epsilon R^m<br> $$</p>
<p> 稀疏表述的 规范惩罚是在损失函数 $J$ 上加一个惩罚项 $\Omega (h)$</p>
<p> $$<br>   \bar J(\theta;X,y) = J(\theta;X,y)+\alpha \Omega (h) \<br>   其中 \alpha \epsilon [0,\infty)<br>$$</p>
<h2 id="7-11-集成学习方法"><a href="#7-11-集成学习方法" class="headerlink" title="7.11 集成学习方法"></a>7.11 集成学习方法</h2><p>  主要思想：独立训练多个模型然后所有模型对测试样本投票来减少泛化错误。依据是，不同模型不会在测试样本上犯同样错误。</p>
<p>  考虑k个回归模型集合，每个模型在每个(单个)样本上误差为 $\epsilon _i$，模型误差来自多变量正太分布，方差为 $E[\epsilon _i^2]=v$ ，协方差期望为 $E[\epsilon _i,\epsilon _j]=c$ ，则所有集成模型的平均误差是 $\frac{1}{k}\sum_i\epsilon _i$ ,期望方差为:</p>
<p>$$<br>   E[(\frac{1}{k}\sum_i \epsilon <em>i)]=\frac{1}{k^2}E[\sum(\epsilon _i^2+\sum</em>{j\ne i}\epsilon _i\epsilon _j)] \<br>   =\frac{1}{k}v+\frac{k-1}{k}c<br>$$</p>
<p>有些情况下，误差完全相关，$c=v$ ，此时平均模型没用。<br>集成学习的期望均方误差与集成规模呈线性递减，也就是集成学习最终至少有其中一个模型的性能。</p>
<p>集成学习方法的简单示例:</p>
<p> <img src="/images/blog/regular5.png" alt="拟合情况"></p>
  <p align="Center">图7.5</p>

<p> 图中第一行是原始数据，进行一些随机替换和重复（如第二行9替换为8，第三行重复9）分别进行训练。其运行机制就是，每个模型使用的数据集大小相同，但是内容不一，会有部分替换和重复。这样来看，每个单独的模型是相对脆弱的，但是平均化输出，整个模型又是健壮的（上图中只有两个模型的输出都是8时，才会有最大置信度）。</p>
<p> 平均模型是极其有效可靠的减少泛化误差的方法，它经常被应用到机器学习竞赛中。BVLC的googlenet使用了6个模型，但是不鼓励在论文中使用，因为可以通过以存储空间换取模型泛化能力。</p>
<h2 id="7-12-dropout"><a href="#7-12-dropout" class="headerlink" title="7.12 dropout"></a>7.12 dropout</h2><p> dropout提供了一种计算量不大，但是强大的正则化方法。它是对一个<strong>模型</strong>族进行正则化处理。</p>
<p> 集成学习方法需要训练多个模型，如果模型巨大，无法实现。dropout训练的是从基础（原始）网络中移除非输出单元构成的全部子网的集合。下图（图7.6）展示了此过程。</p>
<p> <img src="/images/blog/regular6.png" alt="dropout训练过程"></p>
<p align="Center">图7.6</p>

<p>集成学习定义了k个模型，k个从训练数据集中抽样的自集。dropout的目标就是模拟这一过程。训练dropout过程中，我们使用了一个基于<em>mini-batch</em>的学习算法，如<strong>SGD</strong>(随机梯度下降)。每载入一个样本到<em>mini-batch</em>时，对网络中所有输入和隐藏神经元应用一个二进制掩码，决定每个神经元是否被纳入（二进制掩码为1时），每个神经元取掩码值得过程是独立抽样。掩码取值为1的概率在训练之前就固定的，一般取值是，输入神经元0.8，隐藏神经元0.5。下图是一个前馈网络示例:</p>
<p>   <img src="/images/blog/regular7.png" alt="dropout训练过程"><br>  <p align="Center">图7-7</p></p>
<p>集成学习的模型都是独立的(每个模型参数和训练数据)，dropout的每个模型的参数都是原网络参数的一个子集，这种共享机制使得dropout 网络有能力表述指数级的特征。<strong>集成学习</strong>每个子模型分别在其训练子集中收敛，而在dropout中，大部分模型并没有得到完全训练（不是每个模型都达到了收敛状态），其模型太大无法穷尽。dropout网络中，子网的某些部分在迭代中一步步训练，同时参数共享机制使得剩余子网的参数达到一个较好的状态。</p>
<p>使用集成学习模型进行预测时，需要所有模型对预测结果投票，我称此过程为<em>inference</em>。无论是集成学习或者dropout，我们都没有要求模型的精确概率,假设模型是输出一个概率分布，那么集成学习即输出所有概率分布的均值。</p>
<p>  $$<br>    \frac{1}{k}\sum_{i=1}^kp^{(i)}(y|x)<br>  $$<br>  dropout模型中每个由掩码向量 $\mu$ 定义的子模型定义了一个概率分布 $p(y|x,\mu)$，其<em>inference</em>是所有掩码概率分布的均值。所有掩码的算术均值如下:</p>
<p>  $$<br>   \sum_{\mu}p(\mu)p(y|x,\mu)<br>  $$</p>
<p>  由于求和公式包含太多项（指数级），当模型经过一些简化之后很难估计其输出期望（目前为止，深度神经网络的都有不可知的简化）。我们可以通过抽样来模拟<em>inference</em>，即平均多个掩码的输出。一般10-20个掩码足以获得较好的表现。</p>
<p>  然而，有一种更好的方法，一次前向传播即可获得较好的模拟整个集成学习，即使用<strong>几何平均</strong>替换<strong>算术平均</strong>(所有子模型的)。（论文）</p>
<p>  多概率分布的几何均值并不一定是概率分布，为保证多概率的结果依然是概率分布，所有子模型不得使任何事件出现的概率为0，然后使结果呈正态分布。几何均值的非标准(<em>unnormalizalized</em>)概率分布如下:</p>
<p>  $$<br>    \widetilde p_{ensemble}(y|x) =\sqrt[2^d]{\prod_{\mu}p(y|x,\mu)} \<br>    其中d为可能被dropout的神经元数<br>  $$</p>
<p>  此处使用一个 $\mu$ 的正太分布简化表述，其实非正太分布也是可能的。如果要预测输出，需要对模型集合重新标准化:</p>
<p>  $$<br>    P(y|x) =\frac{\widetilde P(y|x)}{\sum_{y^{‘}}\widetilde P(y^{‘}|x)}<br>  $$</p>
<p>  dropout中可以通过估计一个模型的 $p(y|x)$ 来近似 $p_{ensemble}$ ，该模型包含了所有的神经元，但是每个神经元输出要乘以该神经元被保留的概率。此方法可以获得该神经元的期望输出。我们称此方法为<em>scale inference rule</em>，此方法只是一种经验上的技巧，并没有学术论证，但是实际效果很好。</p>
<h3 id="7-12-1-dropout的优点和注意"><a href="#7-12-1-dropout的优点和注意" class="headerlink" title="7.12.1 dropout的优点和注意"></a>7.12.1 dropout的优点和注意</h3><p>  <strong>优点一:</strong> 计算量小，训练时每次更新每个样本的时间复杂度为 $O(n)$，其中 $n$ 为要生成的随机二进制数</p>
<p>  <strong>优点二:</strong> 对模型类型和训练过程没有太大限制。几乎对所有使用分布式表述(<em>distribute representation</em>)并使用SGD的模型都可以很好。</p>
<p>  <strong>注意:</strong> 尽管dropout的每一步代价不高，但是整体权衡下来还是会比较高，作为一种正则化技术，会削弱模型性能，增大模型可以一定程度上抵消这种削弱，但是切记勿得不偿失。一般标签分类任务中，如果样本较少，比如少于5000时，dropout性能一般。</p>
<h2 id="7-13-对抗训练"><a href="#7-13-对抗训练" class="headerlink" title="7.13 对抗训练"></a>7.13 对抗训练</h2><p>在独立同分布(<strong><em>i.i.d</em></strong>)测试中，神经网络已经基本达到人类的分辨能力。为了测试一个神经网络对于隐藏任务的理解能力，我们可以搜寻模型误分类的样本。论文(2010b)发现，即便是达到人类同层次理解能力的神经网络，对使用<strong>优化过程构造</strong>的临界样本（输入相近，但是输出不同）依然会100%犯错。在很多情况下，与输入<code>x</code>十分相近的点<code>x&#39;</code>，人都无法区分对照样本和原始样本的区别，但是网络可以得到完全不同的预测。下图(图7.8)展示了这种差异：</p>
<p>   <img src="/images/blog/regular8.png" alt="对照训练"></p>
<p>一组对照样本应用到GoogLeNet，测试ImageNet。在原始图上添加一个很小的向量，该向量的值是对应输入的损失函数梯度的符号，我们可以改变GoogLeNet对于图像的分类。</p>
<p> 产生这些临街对照样本的基本原因是过度线性化，由线性单元构建的神经网络，其结果也呈高度线性相关，这些线性函数很容易优化。但是，如果输入值是数值的话，线性函数的值可能会产生巨大变化，尤其是高维场合。假若每个维度的输入改变 $\epsilon$，那么权重为w的线性函数会被改变 $\epsilon ||w||_1$，高维场合此值会极大。对照训练可以使得训练数据集中相邻数据具有局部不变性，进而抑制这种高度敏感的局部线性行为。</p>
<p> 纯粹的线性模型无法应对对照训练样本的干扰的，因为它们被强行线性化。神经网络可以表述的函数范围从近线性到局部不变性，因而具有较好稳定性，即可以在学习到训练数据的线性趋势的同时能够有效对抗局部干扰。</p>
<p> <strong>其他用途：</strong> 对照样本可以用来完成半监督学习。数据集中点<code>x</code>没有打标签，模型可能会给它标签 $\widetilde y$,假若模型较好，那么数据点<code>x</code>标签即为 $\widetilde y$ 的概率较高。我们可以搜寻一个对照样本<code>x&#39;</code>使得分类器输出标签为<code>y&#39;</code>，其中 $y’\ne \widetilde y$。对照样本不是使用真实的标签，而是由一个称为<strong>虚拟对照样本</strong> 模型生成的。分类器可能会被训练为给<code>x</code>和<code>x&#39;</code>相同的标签。这会使得分类器逐渐具备对较小变动的未分类数据分类的能力。<strong>motivating</strong>:认为不同类别之间通常不连通，较小扰动不足以使得一种类别与另外一种类别产生关联。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-10-09-regularization-deeplearning/" data-id="ck4ifp1lx001t2wje39nigga2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-10-02-spark-python-example" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-10-02-spark-python-example/" class="article-date">
  <time datetime="2019-12-23T10:45:59.345Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-10-02-spark-python-example/">大数据：spark mllib python使用示例</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="机器学习的背景知识"><a href="#机器学习的背景知识" class="headerlink" title="机器学习的背景知识"></a>机器学习的背景知识</h2><blockquote>
<p>监督学习的中点是** 在规则化参数的同时最小化误差<strong>。最小化误差是为了让我们的模型拟合我们的训练数据，而规则化参数是防止我们的模型过分拟合我们的训练数据。参数太多，会导致我们的模型复杂度上升，容易过拟合，也就是我们的训练误差会很小。但</strong>训练误差<strong>小并不是我们的最终目标，我们的目标是希望模型的</strong>测试误差**小，也就是能准确的预测新的样本。所以，我们需要保证模型“简单”的基础上最小化训练误差，这样得到的参数才具有好的泛化性能（也就是测试误差也小），而模型“简单”就是通过规则函数来实现的。另外，规则项的使用还可以约束我们的模型的特性。这样就可以将人对这个模型的先验知识融入到模型的学习当中，强行地让学习到的模型具有人想要的特性，例如稀疏、低秩、平滑等等。要知道，有时候人的先验是非常重要的。</p>
</blockquote>
<p>来源于：   <a href="http://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/24971995</a></p>
<h1 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h1><h2 id="一-数学公式"><a href="#一-数学公式" class="headerlink" title="一  数学公式"></a>一  数学公式</h2><p>&emsp; &emsp; 许多机器学习方法都可以被转换为一个凸函数优化问题，比如查找凸函数f（自变量是w，在代码中称为权重，自变量有d维）最小值。通常，我们可以将这些写成 $ min_{w\epsilon R^d}f(w) $ ，其目标函数是以下形式<br>$$  f(w) := \lambda, R(w) +\ frac1n \sum_{i=1}^n L(w;x_i,y_i) \label{eq:regPrimal}$$</p>
<p>&emsp;<br>&emsp;<br>此处向量$x_{i}\epsilon R^d$是训练数据，对于$1\leq i\leq n$ 和 $y_{i}\epsilon R$是我们需要预测的标签。如果$L(w;x,y)$可以被表示为 $W^T x$和$y$的函数，则可以调用 <strong><em>linear</em></strong>方法。</p>
<p>&emsp;<br>&emsp;<br>目标函数<strong><em>f</em></strong>分为两部分：控制模型复杂度的正则化部分，模型在训练数据集上误差评估的损失度量部分。损失度量函数$L(w;.)$是一个在域$w$上的凸函数。固定的正则化参数$\lambda \geq 0$(代码中是参数<strong><em>regParam</em></strong>)定义了权衡最小化损失（比如训练误差）和最小化模型复杂度（比如，防止过拟合）之间的平衡。</p>
<h2 id="二-误差函数"><a href="#二-误差函数" class="headerlink" title="二 误差函数"></a>二 误差函数</h2><p>下表概括了损失函数和它们在spark.mllib支持的的梯度和分梯度方法. </p>
<table>
<thead>
<tr>
<th>损失</th>
<th>loss function $L(w;x,y)$$;;;;;;;;$</th>
<th>梯度或分梯度</th>
</tr>
</thead>
<tbody><tr>
<td>hinge loss(SVM)</td>
<td>$max${0,$1-yw^{T}x$},$y \epsilon$ {-1,+1}</td>
<td>$ -y\cdot x (if, yw^Tx &lt; 1);; 0 (otherwise))$</td>
</tr>
<tr>
<td>logstic loss(逻辑回归)</td>
<td>$log(1+exp(-yw^Tx)),y\epsilon {-1,+1}$</td>
<td>$-y(1-\frac {1}{1+exp(-yw^Tx)})\cdot x$</td>
</tr>
<tr>
<td>squared loss(最小二乘)</td>
<td>$\frac {1}{2}(w^Tx-y)^2, y\epsilon R$</td>
<td>$(w^Tx-y)\cdot x$</td>
</tr>
</tbody></table>
<h2 id="三-规则化"><a href="#三-规则化" class="headerlink" title="三 规则化"></a>三 规则化</h2><p>  &emsp;&emsp;规则化的目的是简化模型并避免过拟合，规则化函数Ω(w)也有很多种选择，一般是模型复杂度的单调递增函数，模型越复杂，规则化值就越大。比如，规则化项可以是模型参数向量的范数。然而，不同的选择对参数w的约束不同，取得的效果也不同<br>&emsp;&emsp;关于L1范式和L2范式:</p>
<ul>
<li>L0 范式：L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0，换句话说，让参数W是稀疏的。</li>
<li>L1 范式:  L1范数是指向量中各个元素绝对值之和，也称叫“稀疏规则算子”（Lasso regularization）。<br>既然L0可以实现稀疏，为什么不用L0，而要用L1呢？一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。</li>
<li>L2范式：<br>在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减weight decay”。它的作用是改善过拟合。<br>L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。<br>&emsp;&emsp;目前在 spark.mllib中支持的正则化如下：<table>
<thead>
<tr>
<th>范式</th>
<th>regularizer $R(w)$</th>
<th>梯度或子梯度</th>
</tr>
</thead>
<tbody><tr>
<td>zero(unregularized)</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>L2</td>
<td>$\frac{1}{2}$||w||$_2^2$</td>
<td>w</td>
</tr>
<tr>
<td>L1</td>
<td>$||w||_1$</td>
<td>$sign(w)$</td>
</tr>
<tr>
<td>elastic net</td>
<td>$\alpha||w||_1+(1-\alpha)\frac{1}{2}||w||_2^2$</td>
<td>$\alpha sign(w)+(1-\alpha)w$</td>
</tr>
</tbody></table>
</li>
</ul>
<p><em>此处$sign(w)$是由项$w$中所有$sign(-1,+1)$组成的向量</em></p>
<h2 id="三-优化"><a href="#三-优化" class="headerlink" title="三 优化"></a>三 优化</h2><p>&emsp;&emsp;线性方法使用凸函数来优化目标函数. spark.mllib使用两个方法，SGD和LBFGS（Limited-Memory Quasi-Newton Method）。当前，大多数算法API都支持Stochastic Gradient Descent（随机梯度下降），和少部分支持LBFGS。</p>
<h2 id="四-分类"><a href="#四-分类" class="headerlink" title="四  分类"></a>四  分类</h2><p>&emsp;&emsp;分类旨在将数据项切分到不同类别。<strong><em>spark.mllib</em></strong>提供了两个线性分类方法：线性SVM和逻辑回归。线性SVM只支持二分类，逻辑回归既支持二分类也支持多分类。这两种方法，<strong><em>spark.mllib</em></strong>都支持L1和L2范式规则化。在<strong>MLlib</strong>中训练数据集合以 <em>LabeledPoint</em>类型的RDD代表，其中label（标签）是从0开始0,1,2…的类别索引。<br>&emsp;&emsp;<strong>注意</strong>：指导手册中的，二分类标签$y$要么是 1 要么是 -1，这是为了方便在公式里，但是在<strong>*spark.mllib</strong>里面是以0代表公式中的-1的</p>
<h2 id="五-线性SVM"><a href="#五-线性SVM" class="headerlink" title="五 线性SVM"></a>五 线性SVM</h2><h3 id="5-1-线性SVM概要"><a href="#5-1-线性SVM概要" class="headerlink" title="5.1 线性SVM概要"></a>5.1 线性SVM概要</h3><p>&emsp;&amp;emsp线性SVM的误差函数是由hingle loss给出:$$L(w;x,y) :=max\lbrace0,1-yw^Tx\rbrace$$<br>线性SVM默认使用L2范式规则化训练数据，同时是支持L1范式规则的，此时就变成一个线性问题。<br>线性SVM的输出是一个SVM模型。对于一个新数据点，以$x$表示，模型将会基于$w^Tx$的值预测。默认情况下，如果$w^Tx\geq 0$那么输出为1，否则输出为0。</p>
<h3 id="5-2-示例代码"><a href="#5-2-示例代码" class="headerlink" title="5.2 示例代码"></a>5.2 示例代码</h3><p>&emsp;&emsp;一下代码展示了如何载入数据，创建SVM模型，根据模型预测并计算训练误差。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">学习使用spark.mllib中 SVM模型。代码展示了如何载入数据，创建SVM模型，根据模型预测并计算训练误差。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from pyspark.mllib.classification import SVMWithSGD,SVMModel</span><br><span class="line">from pyspark.mllib.regression import LabeledPoint</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark import SparkConf</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import logging</span><br><span class="line"># Path for spark source folder</span><br><span class="line">os.environ[&#39;SPARK_HOME&#39;]&#x3D;&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6&quot;</span><br><span class="line"># Append pyspark  to Python Path</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python&quot;)</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python\lib\py4j-0.9-src.zip&quot;)</span><br><span class="line"></span><br><span class="line">conf &#x3D; SparkConf()</span><br><span class="line">conf.set(&quot;YARN_CONF_DIR &quot;, &quot;D:\javaPackages\hadoop_conf_dir\yarn-conf&quot;)</span><br><span class="line">conf.set(&quot;spark.driver.memory&quot;, &quot;2g&quot;)</span><br><span class="line">conf.setMaster(&quot;yarn-client&quot;)</span><br><span class="line">conf.setAppName(&quot;TestSVM&quot;)</span><br><span class="line">logger &#x3D; logging.getLogger(&#39;pyspark&#39;)</span><br><span class="line">sc &#x3D; SparkContext(conf&#x3D;conf)</span><br><span class="line">mylog &#x3D; []</span><br><span class="line">#载入数据并解析</span><br><span class="line">def parsePoint(line):</span><br><span class="line">  values &#x3D; [float(x) for x in line.split(&quot; &quot;)]</span><br><span class="line">    return LabeledPoint(values[0],values[1:])</span><br><span class="line">data &#x3D; sc.textFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;SVM&#x2F;sample_svm_data.txt&quot;)</span><br><span class="line"></span><br><span class="line">parseData &#x3D; data.map(parsePoint)</span><br><span class="line">#创建SVM模型</span><br><span class="line">model &#x3D; SVMWithSGD.train(parseData,iterations&#x3D;100)</span><br><span class="line"># 评估模型</span><br><span class="line">labelsAndPoints &#x3D; parseData.map(lambda p:(p.label,model.predict(p.features)))</span><br><span class="line">trainError &#x3D; labelsAndPoints.filter(lambda (v,p):v!&#x3D;p).count()&#x2F;float(parseData.count())</span><br><span class="line">mylog.append(&quot;SVM模型测试，训练误差是:&quot;)</span><br><span class="line">mylog.append(str(trainError))</span><br><span class="line">sc.parallelize(mylog).saveAsTextFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;SVM&#x2F;log&#x2F;&quot;)</span><br><span class="line">#存储和载入模型</span><br><span class="line">model.save(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;SVM&#x2F;SVMModelSave&quot;)</span><br><span class="line">sameModel &#x3D; SVMModel.load(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;SVM&#x2F;SVMModelSave&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="六-逻辑回归"><a href="#六-逻辑回归" class="headerlink" title="六 逻辑回归"></a>六 逻辑回归</h2><h3 id="6-1-逻辑回归概要"><a href="#6-1-逻辑回归概要" class="headerlink" title="6.1 逻辑回归概要"></a>6.1 逻辑回归概要</h3><p>&emsp;&emsp;逻辑回归在二分类预测中广泛使用，其误差函数是下式 logistic loss:$$L(w;x,y):=log(1+\exp(-yw^Tx))$$<br>对于二分类问题，算法的输出结果是一个二项式逻辑回归模型。对于给定新数据点，以$x$表示，使用logistic函数来预测:$$f(z) =\frac{1}{1+e^{-z}}$$。其中$z =w^Tx$，如果$f(w^Tx)&gt;0.5$输出为正，否则为负。与线性SVM不同的是，逻辑回归模型的原始输出有一个概率解释（即，x是正的概率）。<br>&emsp;&emsp;二项式逻辑回归可以生成多项式逻辑回归并用来训练和预测多分类问题。比如说，对于<strong>K</strong>个可能的输出结果，其中一个可以选定为轴，其余<strong>k-1</strong>则与此轴对立。在spark.mllib中第一个被选中的类0就是轴类。<br>&emsp;&emsp;对于多分类问题，算法将会输出一个多项式逻辑回归模型，包含了<strong>k-1</strong>个与第一个类对立的二项式逻辑回归模型。对于新数据点，<strong>k-1</strong>个模型将会运行，其中有最大概率的模型即预测的模型。<br>&emsp;&emsp;spark中实现了两个算法来解决逻辑回归问题：mini-batch gradient（梯度下降）和L-BFGS。参考<a href="http://www.bubuko.com/infodetail-898846.html" target="_blank" rel="noopener">batch-GD， SGD， Mini-batch-GD， Stochastic GD， Online-GD区别</a>  spark推荐L-BFGS梯度下降以获得更快的收敛。</p>
<h3 id="6-2-逻辑回归代码"><a href="#6-2-逻辑回归代码" class="headerlink" title="6.2 逻辑回归代码"></a>6.2 逻辑回归代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">测试逻辑回归代码</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from pyspark.mllib.classification import  LogisticRegressionWithSGD,LogisticRegressionModel</span><br><span class="line">from pyspark.mllib.regression import LabeledPoint</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark import SparkConf</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import logging</span><br><span class="line"></span><br><span class="line"># Path for spark source folder</span><br><span class="line">os.environ[&#39;SPARK_HOME&#39;]&#x3D;&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6&quot;</span><br><span class="line"># Append pyspark  to Python Path</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python&quot;)</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python\lib\py4j-0.9-src.zip&quot;)</span><br><span class="line"></span><br><span class="line">conf &#x3D; SparkConf()</span><br><span class="line">conf.set(&quot;YARN_CONF_DIR &quot;, &quot;D:\javaPackages\hadoop_conf_dir\yarn-conf&quot;)</span><br><span class="line">conf.set(&quot;spark.driver.memory&quot;, &quot;2g&quot;)</span><br><span class="line">conf.setMaster(&quot;yarn-client&quot;)</span><br><span class="line">conf.setAppName(</span><br><span class="line">&quot;TestLogisticRegression&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">logger &#x3D; logging.getLogger(&#39;pyspark&#39;)</span><br><span class="line"></span><br><span class="line">sc &#x3D; SparkContext(conf&#x3D;conf)</span><br><span class="line">mylog &#x3D; []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#载入和解析数据</span><br><span class="line">def parsePoint(line):</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">values &#x3D; [float(x) for x in line.split(&quot; &quot;)]</span><br><span class="line">return LabeledPoint(values[0],values[1:])</span><br><span class="line"></span><br><span class="line">data &#x3D; sc.textFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;logistic_regression&#x2F;sample_svm_data.txt&quot;)</span><br><span class="line">parseData  &#x3D; data.map(parsePoint)</span><br><span class="line">#创建模型</span><br><span class="line">model &#x3D; LogisticRegressionWithSGD.train(parseData)</span><br><span class="line"></span><br><span class="line">#评估模型</span><br><span class="line">labelaAndPoints &#x3D; parseData.map(lambda p:(p.label,model.predict(p.features)))</span><br><span class="line">trainError &#x3D; labelaAndPoints.filter(lambda (k,v):k!&#x3D;v).count()</span><br><span class="line">&#x2F;</span><br><span class="line">float(parseData.count())</span><br><span class="line">mylog.append(&quot;逻辑回归的误差是:&quot;)</span><br><span class="line">mylog.append(trainError)</span><br><span class="line"></span><br><span class="line"># 存储和载入模型</span><br><span class="line">model.save(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;logistic_regression&#x2F;logisticregression_model&#x2F;&quot;)</span><br><span class="line">sc.parallelize(mylog).saveAsTextFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;logistic_regression&#x2F;log&#x2F;&quot;)</span><br><span class="line">logisticregression_model &#x3D; LogisticRegressionModel.load(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;logistic_regression&#x2F;logisticregression_model&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="7-回归"><a href="#7-回归" class="headerlink" title="7 回归"></a>7 回归</h2><p>&emsp;&emsp;<strong>Linear least squares, Lasso, and ridge regression</strong><br>&emsp;&emsp;Linear least squares是回归问题最常用的公式，其误差函数如下：$$L(w;x,y):=\frac{1}{2}(w^Tx-y)^{2}$$<br>使用不同的规则参数将会派生出不同的相关回归方法；其中的 <strong>ordinary least squares</strong>和<strong>linear least squares</strong>不使用规则参数，ridge regression(岭回归)使用L2规则参数，Lasso使用L1规则参数。所有的这些模型，其平均误差或者训练误差$$\frac{1}{n}\sum_{i=1}^n(w^Tx-y_i)^2$$ 即均方差。<br>&emsp;&emsp;一下代码展示了如何载入数据、转换为LabeledPoint类型的RDD。然后使用 LinearRegressionWithSGD来创建简单线性模型来预测标签值。最后再计算均方差来评估适应度。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">from pyspark.mllib.regression import LabeledPoint,LinearRegressionWithSGD,LinearRegressionModel</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark import SparkConf</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import logging</span><br><span class="line"># Path for spark source folder</span><br><span class="line">os.environ[&#39;SPARK_HOME&#39;]&#x3D;&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6&quot;</span><br><span class="line"># Append pyspark  to Python Path</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python&quot;)</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python\lib\py4j-0.9-src.zip&quot;)</span><br><span class="line"></span><br><span class="line">conf &#x3D; SparkConf()</span><br><span class="line">conf.set(&quot;YARN_CONF_DIR &quot;, &quot;D:\javaPackages\hadoop_conf_dir\yarn-conf&quot;)</span><br><span class="line">conf.set(&quot;spark.driver.memory&quot;, &quot;2g&quot;)</span><br><span class="line">conf.setMaster(&quot;yarn-client&quot;)</span><br><span class="line">conf.setAppName(&quot;TestSimpleLinearRegression&quot;)</span><br><span class="line">logger &#x3D; logging.getLogger(&#39;pyspark&#39;)</span><br><span class="line">sc &#x3D; SparkContext(conf&#x3D;conf)</span><br><span class="line"></span><br><span class="line">#载入数据</span><br><span class="line">def parsePoint(line):</span><br><span class="line">  values &#x3D; [float(x) for x in line.replace(&#39;,&#39;,&#39; &#39;).split(&#39; &#39;)]</span><br><span class="line">    return LabeledPoint(values[0],values[1:])</span><br><span class="line"></span><br><span class="line">mylog &#x3D; []</span><br><span class="line">data &#x3D; sc.textFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;linear_regression&#x2F;data&#x2F;lpsa.data&quot;)</span><br><span class="line">parseData &#x3D; data.map(parsePoint)</span><br><span class="line">#创建模型</span><br><span class="line">model &#x3D; LinearRegressionWithSGD.train(parseData,iterations &#x3D; 10,step&#x3D;0.000001)</span><br><span class="line">#评估模型误差</span><br><span class="line">valuesAndPres &#x3D; parseData.map(lambda p:(p.label,model.predict(p.features)))</span><br><span class="line">MSE &#x3D; valuesAndPres.map(lambda (v,p):(v-p)**2).reduce(lambda x,y:x+y)&#x2F;valuesAndPres.count()</span><br><span class="line">mylog.append(&quot;简单线性回归误差是：&quot;)</span><br><span class="line">mylog.append(MSE)</span><br><span class="line">sc.parallelize(mylog).saveAsTextFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;linear_regression&#x2F;log&quot;)</span><br><span class="line">#存储 和使用模型</span><br><span class="line">model.save(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;linear_regression&#x2F;SimpleLinearRegressionModel&quot;)</span><br><span class="line">sameMode &#x3D; LinearRegressionModel.load(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;linear_regression&#x2F;SimpleLinearRegressionModel&quot;)&lt;&#x2F;pre&gt;</span><br></pre></td></tr></table></figure>

<h3 id="流线性回归"><a href="#流线性回归" class="headerlink" title="流线性回归"></a>流线性回归</h3><p>如果数据是以流的形式到达，在线适配回归模型、新数据到达时跟更新模型参数是很有用的。<em>spark.mllib<em>当前支持使用 *</em>ordinary least squares**的线性回归。适应过程类似于离线使用，一批新数据到达时预测适应值，以此来不断地更新流中的新数据的回应值（回归值）。<br>&emsp;&emsp;如下代码演示了如何训练和测试来自两个不同文本格式的输入流，将流解析成labeled point,使用第一个流来拟合回归模型，并在第二个流中作预测。注意，当训练目录 *”/home/xiatao/machine_learing/streaming_linear_regression/data</em> 新增数据时，相应的预测目录<em>/home/xiatao/machine_learing/streaming_linear_regression/predict</em>就会产生相应的结果。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"># 流线性回归模型测试</span><br><span class="line">from pyspark.mllib.linalg import Vectors</span><br><span class="line">from pyspark.mllib.regression import StreamingLinearRegressionWithSGD</span><br><span class="line">from pyspark.streaming import StreamingContext</span><br><span class="line">from pyspark.mllib.regression import LabeledPoint</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark import SparkConf</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import logging</span><br><span class="line"># Path for spark source folder</span><br><span class="line">os.environ[&#39;SPARK_HOME&#39;]&#x3D;&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6&quot;</span><br><span class="line"># Append pyspark  to Python Path</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python&quot;)</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python\lib\py4j-0.9-src.zip&quot;)</span><br><span class="line"></span><br><span class="line">conf &#x3D; SparkConf()</span><br><span class="line">conf.set(&quot;YARN_CONF_DIR &quot;, &quot;D:\javaPackages\hadoop_conf_dir\yarn-conf&quot;)</span><br><span class="line">conf.set(&quot;spark.driver.memory&quot;, &quot;2g&quot;)</span><br><span class="line">conf.setMaster(&quot;yarn-client&quot;)</span><br><span class="line">conf.setAppName(&quot;TestStreamLinearRegression&quot;)</span><br><span class="line">logger &#x3D; logging.getLogger(&#39;pyspark&#39;)</span><br><span class="line">sc &#x3D; SparkContext(conf&#x3D;conf)</span><br><span class="line">mylog &#x3D; []</span><br><span class="line"></span><br><span class="line">#第一步创建 StreamingContextssc &#x3D; StreamingContext(sc,1)</span><br><span class="line"></span><br><span class="line">#载入和解析数据</span><br><span class="line">def parse(lp):</span><br><span class="line">  label &#x3D; float(lp[ lp.find(&#39;(&#39;)+1:lp.find(&#39;,&#39;)  ])</span><br><span class="line">    vec &#x3D; Vectors.dense(lp[lp.find(&#39;[&#39;)+1:lp.find(&#39;,&#39;)].split(&#39;,&#39;))</span><br><span class="line">    return LabeledPoint(label,vec)</span><br><span class="line"># 训练集和测试集的数据每行的格式为 (y,[x1,x2,x3]),其中y是标签，x1,x2,x3是特征。</span><br><span class="line"># 训练集中数据更新时，测试集目录就会出现预测值。并且数据越多，预测越准确</span><br><span class="line">trainingData &#x3D; ssc.textFileStream(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;streaming_linear_regression&#x2F;data&quot;).map(parse).cache()</span><br><span class="line">testData &#x3D; ssc.textFileStream(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;streaming_linear_regression&#x2F;predict&quot;).map(parse)</span><br><span class="line">#创建 权值为0的初始化模型</span><br><span class="line">numFeatures&#x3D; 3</span><br><span class="line">model &#x3D; StreamingLinearRegressionWithSGD()</span><br><span class="line">model.setInitialWeights([0.0,0.0,0.0])</span><br><span class="line"># 为训练流和测试流登记，并启动作业</span><br><span class="line">model.trainOn(trainingData)</span><br><span class="line">mylog.append(model.predictOnValues(testData.map(lambda lp:(lp.label,lp.features))))</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()&lt;&#x2F;pre&gt;</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-10-02-spark-python-example/" data-id="ck4ifp1lw001p2wje8ehebuqi" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-10-02-spark-mllib-desciontree" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-10-02-spark-mllib-desciontree/" class="article-date">
  <time datetime="2019-12-23T10:45:59.343Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-10-02-spark-mllib-desciontree/">大数据：spark mllib决策树</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一-基本算法"><a href="#一-基本算法" class="headerlink" title="一 基本算法"></a>一 基本算法</h1><p>&emsp;&emsp;决策树是一个在特征空间递归执行二分类的贪心算法。决策树预测所有叶子节点分区的标签。为了在树的每个节点最大化信息增益，其每个分区都是基于贪心策略从可能分裂集合里选择一个最佳分裂(split)。也即，每个数节点分裂的选择是从集合 $argmaxIG(D,s)$，其中$IG(D,s)$是信息增益，而s是应用到数据集D上的分裂。</p>
<h2 id="二-节点不纯度和信息增益"><a href="#二-节点不纯度和信息增益" class="headerlink" title="二 节点不纯度和信息增益"></a>二 节点不纯度和信息增益</h2><p>节点不纯度是用以衡量节点同质化标签的度量。当前为了分类提供两种不纯度方法（Gini impurity和信息熵），为回归提供了一个不纯度度量（方差）。</p>
<table>
<thead>
<tr>
<th>impurity(不纯度)</th>
<th>作业</th>
<th>公式</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>Gini impurity</td>
<td>分类</td>
<td>$\sum_{i=1}^cf_i(1-f_i)$</td>
<td>$f_i$ 是某个节点上标签为i的频率,C是标签数据</td>
</tr>
<tr>
<td>信息熵</td>
<td>分类</td>
<td>$\sum_{i=1}^c-f_i\log(f_i)$</td>
<td>$f_i $是某个节点上标签为i的频率,C是标签数据</td>
</tr>
<tr>
<td>方差</td>
<td>回归</td>
<td>$\frac{1}{N}\sum_{i=1}^N(y_i-\mu)^2$</td>
<td>$y_i$是某个数据实例的标签，N是数据实例的总数，$\mu$是由$\frac{1}{N}\sum_{i=1}^Ny_i$均值</td>
</tr>
</tbody></table>
<p>信息增益是衡量父母节点的不纯度与两个孩子节点不纯度权值求和的差异。假设一个分裂$s$将数据集 D(包含N个元素)分裂成两个子集合 $D_{left}$（包含$N_{left}$个元素）和 $D_{right}$ (包含 $N_{right}$ )，相应的信息增益是:</p>
<p>$$</p>
<p>IG(D,s) = Impurity(D)-\frac{N_{left}}{N}Impurity(D_{left})-\frac{N_{right}}{N}Impurity(D_{right})</p>
<p>$$</p>
<h2 id="三-分裂候选"><a href="#三-分裂候选" class="headerlink" title="三 分裂候选"></a>三 分裂候选</h2><h3 id="3-1-连续特征"><a href="#3-1-连续特征" class="headerlink" title="3.1 连续特征"></a>3.1 连续特征</h3><p>对于小数据集在单机上的实现，对每个连续特征来说其分裂候选一般是该特征的唯一值。有些实现会将特征值排序然后使用排序后的唯一值作为分裂候选以达到更快的计算速度。<br>&emsp;&emsp;对于大规模分布式数据来说排序的特征值是代价高昂的。通过对部分抽样数据进行位数计算来近似计算其分裂候选，以此来实现排序。排序后的分裂会创建“分箱”，可以通过参数<strong><em>maxBins</em></strong>来指定最大分箱数。<br>&emsp;&emsp;注意，分箱数目可以比数据实例数目大（这种情况比较少见，由于默认的<strong><em>maxBins</em></strong>是32）。如果分裂时条件不满足了，决策树会自动减少分箱数目。</p>
<h3 id="3-2-分类特征"><a href="#3-2-分类特征" class="headerlink" title="3.2 分类特征"></a>3.2 分类特征</h3><p>对于一个分类特征，有M个可能的取值（类别），可能会有$2^{M-1}-1$个分裂候选。对于二分类(0/1)和回归，我们可以通过对类别特征排序（用平均标签）将分裂候选减少至<strong>M-1</strong>。例如对于某个二分类问题，1个类别特征，3个分类A,B,C，相应的标签为1的比例为0.2,0.6,0.4，类别特征排序为A,C,B。两个分裂候选是A|C,B和A,C|B，其中竖线代表分裂。<br>&emsp;&emsp;在多分类中，所有的$2^{M-1}-1$个可能的分裂无论何时都可能会被使用到。如果$2^{M-1}-1$比参数<strong><em>maxBins</em></strong>大，使用一个与二分类和回归分析中类似的启发式方法。<strong><em>M</em></strong>个类别特征都是根据不纯度排序的。</p>
<h2 id="四-停止规则"><a href="#四-停止规则" class="headerlink" title="四 停止规则"></a>四 停止规则</h2><p>递归的构建树过程会在某个节点满足以下条件时停止：</p>
<ol>
<li><p>树深度已经等于训练参数<strong><em>maxDepth</em></strong>。</p>
</li>
<li><p>分裂候选产生的信息增益都小于参数<strong><em>minInfoGain</em></strong>。</p>
</li>
<li><p>分裂候选已经不能产生孩子节点，满足每个孩子节点有至少<strong><em>minInstancePerNode</em></strong>训练集实例。</p>
</li>
</ol>
<h2 id="五-参数设置问题"><a href="#五-参数设置问题" class="headerlink" title="五 参数设置问题"></a>五 参数设置问题</h2><p>以下参数需要设置但不需要调节。</p>
<ol>
<li><p><strong>algo</strong>：分类还是回归。</p>
</li>
<li><p><strong>numClass</strong>:分类的类别数目（只对分类）</p>
</li>
<li><p><strong>categoricalFeaturesInfo</strong>：设置哪些特征是类别以及每个这些特征值可以取多少类别值。此参数以map的形式给出，所有不在这个map中的特征都会被视为连续的。map的取值示例如下:</p>
</li>
</ol>
<ul>
<li><p>Map(0-&gt;2,4-&gt;10….) 指明，特征0 是二分类（取值为0或1），特征4有10个类别（取值是0-9）</p>
</li>
<li><p><strong>注意</strong>：你并不需要配置 <em>categoricalFeaturesInfo</em>。算法依然会运行并给出不错的结果，然而如果可特征化的值设计得很好，算法可以有更好的性能。</p>
</li>
</ul>
<h2 id="六-停止标准"><a href="#六-停止标准" class="headerlink" title="六 停止标准"></a>六 停止标准</h2><p>&emsp;&emsp;这些参数决定算法何时停止（增加节点），调节以下参数时，注意在测试数据集上验证并避免过拟合。</p>
<ul>
<li><p><strong>maxDepth</strong>:树的最大深度。越深的树（可能会获取更高的准确率）计算代价越高，但是它们也更耗时同时更可能过拟合。</p>
</li>
<li><p><strong>minInstancesPerNode</strong>:对于一个可能会进一步分裂的节点，它的子节点必须有至少这么多个训练实例数据。此参数一般和随机森林一起使用，因为这些会比单独的树要训练得更深。</p>
</li>
<li><p><strong>minInfoGain</strong>:对于可能会进一步分裂的节点，分裂必须增加这么多信息增益。</p>
</li>
</ul>
<h2 id="七-调节参数"><a href="#七-调节参数" class="headerlink" title="七 调节参数"></a>七 调节参数</h2><p>&emsp;&emsp;这些参数可以调节，但是注意在测试数据集上验证并避免过拟合。</p>
<ul>
<li><strong>maxBins</strong>:离散化连续型变量时使用的分箱数。增加 <strong>maxBins</strong>使得算法考虑更多的分裂候选并产生更细粒度的分裂决策，然而会增加计算消耗和组件间沟通成本。注意：对于任何可类别话的特征，参数<strong>maxBins</strong>必须至少是类别<strong>M</strong>最大值。</li>
<li><strong>maxMemoryInMB</strong>:进行统计时使用的内存量。默认值保守取到256MB，足以使得决策树在大多数场景适用。增大此参数可以减少数据传输让训练过程更快。<br>实现细节：为了更快的处理速度，决策树算法收集每组会分裂的节点的统计数据（而不是一次一个节点）。能放入一个组中处理的节点是由内存需求决定的（不同的特征不同）。参数<strong>maxMemoryInMB</strong>配置了每个使用这些统计的worker的内存限制。</li>
<li><strong>subsamplingRate</strong>:学习决策树的训练数据集比例。这个参数大多用在训练树的集合（随机森林、GradientBoostedTrees（渐变提振树））中，用以在袁术数据集中抽样数据。在单个决策树中，此参数并没有那么重要，因为训练数据并不是最大的限制。</li>
<li><strong>impurity</strong>:在分裂候选中筛选衡量不纯度的参数，这个参数必须与<strong>algo</strong>参数相对应。</li>
</ul>
<h2 id="八-缓存和检查点"><a href="#八-缓存和检查点" class="headerlink" title="八 缓存和检查点"></a>八 缓存和检查点</h2><p>当参数<strong>maxDepth</strong>设置得很大时，有必要开启节点ID缓存和检查点。在随机森林中，如何参数<strong>numTrees</strong>设置得很大时，也比较有用。</p>
<ul>
<li><strong>useNodeIdCache</strong>：如何此参数设置为* ture*，算法将会避免在每次迭时传入当前模型（tree ,trees）。算法默认会让当前模型与executors交流，使得executors每个树节点能够达到训练实例要求。当开启此参数时，算法将会缓存这部分信息。</li>
</ul>
<p>节点ID缓存会生成一些RDD（每次迭代时生成一个）。这种很长的lineage(血缘)会导致性能问题，但是检查点中间RDD可以缓和这些问题，<strong>注意</strong>只有当<strong><em>useNodeIdCache</em></strong>设置为<strong><em>true</em></strong>检查点才可用。</p>
<ul>
<li><strong>checkpointDir</strong>:节点ID缓存RDD的检查点目录。</li>
<li><strong>checkpointInteral</strong>:节点ID缓存RDD的频率，设置的过小会导致过量的写入HDFS，设置得太大时会使得executors失败并需要重新计算时等待太长。</li>
</ul>
<h2 id="九-代码实例"><a href="#九-代码实例" class="headerlink" title="九 代码实例"></a>九 代码实例</h2><p>以下代码展示了如何载入一个<strong>LIBSVM</strong>数据文件，解析成一个<strong>LabeledPoint</strong>RDD，然后使用决策树，使用Gini不纯度作为不纯度衡量指标，最大树深度是5.测试误差用来计算算法准确率。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">测试决策树</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import logging</span><br><span class="line">from pyspark.mllib.tree import DecisionTree,DecisionTreeModel</span><br><span class="line">from pyspark.mllib.util import MLUtils</span><br><span class="line"></span><br><span class="line"># Path for spark source folder</span><br><span class="line">os.environ[&#39;SPARK_HOME&#39;]&#x3D;&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6&quot;</span><br><span class="line"># Append pyspark  to Python Path</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python&quot;)</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python\lib\py4j-0.9-src.zip&quot;)</span><br><span class="line"></span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark import SparkConf</span><br><span class="line"></span><br><span class="line">conf &#x3D; SparkConf()</span><br><span class="line">conf.set(&quot;YARN_CONF_DIR &quot;, &quot;D:\javaPackages\hadoop_conf_dir\yarn-conf&quot;)</span><br><span class="line">conf.set(&quot;spark.driver.memory&quot;, &quot;2g&quot;)</span><br><span class="line"></span><br><span class="line">#conf.set(&quot;spark.executor.memory&quot;, &quot;1g&quot;)</span><br><span class="line">#conf.set(&quot;spark.python.worker.memory&quot;, &quot;1g&quot;)</span><br><span class="line">conf.setMaster(&quot;yarn-client&quot;)</span><br><span class="line">conf.setAppName(&quot;TestDecisionTree&quot;)</span><br><span class="line">logger &#x3D; logging.getLogger(&#39;pyspark&#39;)</span><br><span class="line">sc &#x3D; SparkContext(conf&#x3D;conf)</span><br><span class="line"></span><br><span class="line">mylog &#x3D; []</span><br><span class="line">#载入和解析数据文件为 LabeledPoint RDDdata &#x3D; MLUtils.loadLibSVMFile(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;&quot;)</span><br><span class="line">#将数据拆分成训练集合测试集</span><br><span class="line">(trainingData,testData) &#x3D; data.randomSplit([0.7,0.3])</span><br><span class="line"></span><br><span class="line">##训练决策树模型</span><br><span class="line">#空的 categoricalFeauresInfo 代表了所有的特征都是连续的</span><br><span class="line">model &#x3D; DecisionTree.trainClassifier(trainingData, numClasses&#x3D;2,categoricalFeaturesInfo&#x3D;&#123;&#125;,impurity&#x3D;&#39;gini&#39;,maxDepth&#x3D;5,maxBins&#x3D;32)</span><br><span class="line"></span><br><span class="line"># 在测试实例上评估模型并计算测试误差</span><br><span class="line"></span><br><span class="line">predictions &#x3D; model.predict(testData.map(lambda x:x.features))</span><br><span class="line">labelsAndPoint &#x3D; testData.map(lambda lp:lp.label).zip(predictions)</span><br><span class="line">testMSE &#x3D; labelsAndPoint.map(lambda (v,p):(v-p)**2).sum()&#x2F;float(testData.count())</span><br><span class="line">mylog.append(&quot;测试误差是&quot;)</span><br><span class="line">mylog.append(testMSE)</span><br><span class="line"></span><br><span class="line">#存储模型</span><br><span class="line"></span><br><span class="line">model.save(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;&quot;)</span><br><span class="line">sc.parallelize(mylog).saveAsTextFile(&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;log&quot;)</span><br><span class="line">sameModel &#x3D; DecisionTreeModel.load(sc,&quot;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;&quot;)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-10-02-spark-mllib-desciontree/" data-id="ck4ifp1lv001n2wjedsme7ute" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-10-01-regular-attachment" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-10-01-regular-attachment/" class="article-date">
  <time datetime="2019-12-23T10:45:59.342Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-10-01-regular-attachment/">深度学习：参数正则化参考资料</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Hessian矩阵"><a href="#Hessian矩阵" class="headerlink" title="Hessian矩阵"></a>Hessian矩阵</h2><p> 是一个多元函数的二阶偏导数构成的方阵，描述了函数的局部曲率。若多元函数在临界点处一阶导数为0，此时仅仅通过一阶导数无法判断是极大值还是极小值，此时通过Hessian矩阵</p>
<ul>
<li><p>若$H(m)$是正定矩阵，则M处为局部极大值。</p>
</li>
<li><p>若$H(m)$是负定矩阵，则M处为局部极小值。</p>
</li>
<li><p>若$H(m)$是不定矩阵，则M处不是极值。</p>
</li>
</ul>
<h2 id="泰勒级数"><a href="#泰勒级数" class="headerlink" title="泰勒级数"></a>泰勒级数</h2><p>泰勒级数（英语：Taylor series）用无限项连加式——级数来表示一个函数，这些相加的项由函数在某一点的导数求得。如果  在点 $x=x_0$ 具有任意阶导数，则幂级数</p>
<p>$$<br>\sum_{n=0}^{\infty}\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n=f(x_0)+f’(x_0)(x-x_0)+\frac{f’’(x_0))}{2!}(x-x_0)^2+…<br>$$</p>
<p>称为在点 $x_0$ 处的泰勒级数</p>
<h2 id="拉格朗日乘子和KKT条件"><a href="#拉格朗日乘子和KKT条件" class="headerlink" title="拉格朗日乘子和KKT条件"></a>拉格朗日乘子和KKT条件</h2><p>在求取有约束条件的优化问题时，拉格朗日乘子法（Lagrange Multiplier) 和KKT条件是非常重要的两个求取方法，对于等式约束的优化问题，可以应用拉格朗日乘子法去求取最优值；如果含有不等式约束，可以应用KKT条件去求取。当然，这两个方法求得的结果只是必要条件，只有当是凸函数的情况下，才能保证是充分必要条件。KKT条件是拉格朗日乘子法的泛化。之前学习的时候，只知道直接应用两个方法，但是却不知道为什么拉格朗日乘子法（Lagrange Multiplier) 和KKT条件能够起作用，为什么要这样去求取最优值呢？</p>
<p>下面将首先把什么是拉格朗日乘子法（Lagrange Multiplier) 和KKT条件叙述一下；然后开始分别谈谈为什么要这样求最优值。</p>
<h3 id="一-拉格朗日乘子法（Lagrange-Multiplier-和KKT条件"><a href="#一-拉格朗日乘子法（Lagrange-Multiplier-和KKT条件" class="headerlink" title="一. 拉格朗日乘子法（Lagrange Multiplier) 和KKT条件"></a>一. 拉格朗日乘子法（Lagrange Multiplier) 和KKT条件</h3><p>通常我们需要求解的最优化问题有如下几类：</p>
<p>1.无约束优化问题，可以写为:</p>
<p>$$<br>                    min f(x);<br>$$</p>
<p>2.有等式约束的优化问题，可以写为:</p>
<p>$$</p>
<pre><code>min f(x), \\
s.t. h_i(x) = 0;i =1, ..., n</code></pre><p>$$                                    </p>
<p>3.有不等式约束的优化问题，可以写为：</p>
<p>$$<br>    min f(x), \<br>    s.t. g_i(x) &lt;= 0; i =1, …, n\<br>    h_j(x) = 0; j =1, …, m<br>$$</p>
<p>对于第(1)类的优化问题，常常使用的方法就是Fermat定理，即使用求取f(x)的导数，然后令其为零，可以求得候选最优值，再在这些候选值中验证；如果是凸函数，可以保证是最优解。</p>
<p>对于第(2)类的优化问题，常常使用的方法就是拉格朗日乘子法（Lagrange Multiplier) ，即把等式约束 $h_i(x)$ 用一个系数与 $f(x)$ 写为一个式子，称为拉格朗日函数，而系数称为拉格朗日乘子。通过拉格朗日函数对各个变量求导，令其为零，可以求得候选值集合，然后验证求得最优值。</p>
<p>对于第(3)类的优化问题，常常使用的方法就是KKT条件。同样地，我们把所有的等式、不等式约束与f(x)写为一个式子，也叫拉格朗日函数，系数也称拉格朗日乘子，通过一些条件，可以求出最优值的必要条件，这个条件称为KKT条件。</p>
<ul>
<li><p><strong>拉格朗日乘子法（Lagrange Multiplier):</strong> 对于等式约束，我们可以通过一个拉格朗日系数a 把等式约束和目标函数组合成为一个式子 $L(a, x) = f(x) + a*h(x)$, 这里把a和 $h(x)$ 视为向量形式，a是横向量，h(x)为列向量。然后求取最优值，可以通过对 $L(a,x)$ 对各个参数求导取零，联立等式进行求取，这个在高等数学里面有讲，但是没有讲为什么这么做就可以，在后面，将简要介绍其思想。</p>
</li>
<li><p><strong>KKT条件:</strong> 对于含有不等式约束的优化问题，如何求取最优值呢？常用的方法是KKT条件，同样地，把所有的不等式约束、等式约束和目标函数全部写为一个式子 $L(a,b,x)=f(x)+a<em>g(x)+b</em>h(x)$ ，KKT条件是说最优值必须满足以下条件：</p>
<ol>
<li><p>$L(a, b, x)$ 对 $x$ 求导为零</p>
</li>
<li><p>$h(x) =0$</p>
</li>
<li><p>$a*g(x) = 0$</p>
</li>
</ol>
<p>求取这三个等式之后就能得到候选最优值。其中第三个式子非常有趣，因为$g(x)&lt;=0$，如果要满足这个等式，必须$a=0$或者$g(x)=0$ . 这是SVM的很多重要性质的来源，如支持向量的概念。</p>
</li>
</ul>
<h3 id="二-为什么拉格朗日乘子法（Lagrange-Multiplier-和KKT条件能够得到最优值？"><a href="#二-为什么拉格朗日乘子法（Lagrange-Multiplier-和KKT条件能够得到最优值？" class="headerlink" title="二. 为什么拉格朗日乘子法（Lagrange Multiplier) 和KKT条件能够得到最优值？"></a>二. 为什么拉格朗日乘子法（Lagrange Multiplier) 和KKT条件能够得到最优值？</h3><p>为什么要这么求能得到最优值？先说拉格朗日乘子法，设想我们的目标函数 $z = f(x)$, x是向量, z取不同的值，相当于可以投影在x构成的平面（曲面）上，即成为等高线，如下图，目标函数是f(x, y)，这里x是标量，虚线是等高线，现在假设我们的约束 $g(x)=0$，x是向量，在x构成的平面或者曲面上是一条曲线，假设g(x)与等高线相交，交点就是同时满足等式约束条件和目标函数的可行域的值，但肯定不是最优值，因为相交意味着肯定还存在其它的等高线在该条等高线的内部或者外部，使得新的等高线与目标函数的交点的值更大或者更小，只有到等高线与目标函数的曲线相切的时候，可能取得最优值，如下图所示，即等高线和目标函数的曲线在该点的法向量必须有相同方向，所以最优值必须满足：$f(x)的梯度 = a* g(x)$ 的梯度，a是常数，表示左右两边同向。这个等式就是$L(a,x)$ 对参数求导的结果。</p>
<p><img src="/images/blog/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A51.jpg" alt="拉格朗日"></p>
<p>而KKT条件是满足强对偶条件的优化问题的必要条件，可以这样理解：我们要求</p>
<p>$$<br>min f(x), L(a, b, x) = f(x) + a\times g(x) + b\times h(x)，a&gt;=0，<br>$$</p>
<p>我们可以把f(x)写为：$max_{a,b} L(a,b,x)$ 为什么呢？因为 $h(x)=0, g(x)&lt;=0$ ，现在是取 $L(a,b,x)$ 的最大值, $ag(x)\le0$ ,所以 $L(a,b,x)$ 只有在 $a\times g(x)=0$ 的情况下才能取得最大值，否则，就不满足约束条件，因此 $max_{a,b}L(a,b,x)$ 在满足约束条件的情况下就是f(x)，因此我们的目标函数可以写为 $min_xmax_{a,b}L(a,b,x)$ 。如果用对偶表达式： $max_{a,b}min_xL(a,b,x)$ ，由于我们的优化是满足强对偶的（强对偶就是说对偶式子的最优值是等于原问题的最优值的），所以在取得最优值x0的条件下，它满足</p>
<p>$$<br>f(x0) = max_{a,b} min_x  L(a,b,x) = min_x max_{a,b} L(a,b,x) =f(x0)，<br>$$</p>
<p>我们来看看中间两个式子发生了什么事情：</p>
<p>$$<br> f(x0) = max_{a,b} min_x  L(a,b,x) \<br> =  max_{a,b} min_x f(x) + a\times g(x) + b\times h(x) \<br> =  max_{a,b} f(x0)+a\times g(x0)+b\times h(x0) = f(x0)<br>$$</p>
<p>可以看到上述本质上是说 $min_xf(x)+a\times g(x)+b\times h(x)$ 在 $x_0$ 取得了最小值，用fermat定理，即是说对于函数 $f(x)+a\times g(x)+b\times h(x)$，求取导数要等于零，即 $f(x)的梯度+a\times g(x)的梯度+b*h(x)的梯度 = 0$</p>
<p>这就是kkt条件中第一个条件：$L(a, b, x)$ 对 $x$ 求导为零。</p>
<p>而之前说明过，$a*g(x) = 0$ ，这是kkt条件的第2个条件，当然已知的条件 $h(x)=0$ 必须被满足，所有上述说明，满足强对偶条件的优化问题的最优值都必须满足KKT条件，即上述说明的三个条件。可以把KKT条件视为是拉格朗日乘子法的泛化。</p>
<h2 id="适定、超定和欠定方程的概念"><a href="#适定、超定和欠定方程的概念" class="headerlink" title="适定、超定和欠定方程的概念"></a>适定、超定和欠定方程的概念</h2><p>矩阵的每一行代表一个方程，m行代表m个线性联立方程。 n列代表n个变量。如果m是独立方程数，根据m&lt;n、m=n、m&gt;n确定方程是 <code>欠定</code>、<code>适定</code> 还是 <code>超定</code>。</p>
<h3 id="超定方程组"><a href="#超定方程组" class="headerlink" title="超定方程组"></a>超定方程组</h3><p> 即方程个数大于未知量个数的方程组。</p>
<p> 对于方程组Ra=y，R为n×m矩阵，如果R列满秩，且n&gt;m</p>
<p> 超定方程一般是不存在解的矛盾方程。</p>
<p> 例如，如果给定的三点不在一条直线上， 我们将无法得到这样一条直线，使得这条直线同时经过给定这三个点。 也就是说给定的条件（限制）过于严格， 导致解不存在。在实验数据处理和曲线拟合问题中，求解超定方程组非常普遍。比较常用的方法是最小二乘法。形象的说，就是在无法完全满足给定的这些条件的情况下，求一个最接近的解。</p>
<p> 曲线拟合的最小二乘法要解决的问题，实际上就是求以上超定方程组的最小二乘解的问题。</p>
<h3 id="欠定方程组"><a href="#欠定方程组" class="headerlink" title="欠定方程组:"></a>欠定方程组:</h3><p> 即方程个数小于未知量个数的方程组。<br> 对于方程组Ra=y，R为n×m矩阵，且n&lt;m。则方程组有无穷多组解，此时称方程组为欠定方程组。<br> 内点法和梯度投影法是目前解欠定方程组的常用方法。</p>
<h2 id="奇异矩阵"><a href="#奇异矩阵" class="headerlink" title="奇异矩阵"></a>奇异矩阵</h2><p><strong>概念</strong>：奇异矩阵是线性代数的概念，就是对应的行列式等于0的方阵</p>
<p><strong>判断方法</strong>：首先，看这个矩阵是不是方阵（即行数和列数相等的矩阵。若行数和列数不相等，那就谈不上奇异矩阵和非奇异矩阵）。 然后，再看此矩阵的行列式|A|是否等于0，若等于0，称矩阵A为奇异矩阵；若不等于0，称矩阵A为非奇异矩阵。 同时，由|A|≠0可知矩阵A可逆，这样可以得出另外一个重要结论:可逆矩阵就是非奇异矩阵，非奇异矩阵也是可逆矩阵。　如果A为奇异矩阵，则AX=0有无穷解，AX=b有无穷解或者无解。如果A为非奇异矩阵，则AX=0有且只有唯一零解，AX=b有唯一解</p>
<h2 id="多元线性回归参数估计问题"><a href="#多元线性回归参数估计问题" class="headerlink" title="多元线性回归参数估计问题"></a>多元线性回归参数估计问题</h2><h3 id="回归参数的最小二乘估计"><a href="#回归参数的最小二乘估计" class="headerlink" title="回归参数的最小二乘估计"></a>回归参数的最小二乘估计</h3><p>对于含有k个解释变量的多元线性回归模型</p>
<p>$$<br> Y_i=\beta_0+\beta_1X_{1i}+\beta_2X_{2i}+…+\beta_kX_{ki}+\mu_i<br>$$</p>
<p>设 $\bar \beta_0,\bar \beta_2,\bar \beta_2,..\bar \beta_k$ 分别作为参数 $\beta_0,\beta_1,\beta_2,…\beta_k$ 的估计量，得样本回归方程为：</p>
<p>$$<br>   Y_i=\bar \beta_0+\bar \beta_1X_{1i}+\bar \beta_2X_{2i}+…+\bar \beta_kX_{ki}<br>$$</p>
<p>观测值 $Y_i$ 与回归值 $\bar Y_i$ 的残差 $e_i$ 为：</p>
<p> $$<br>  e_i=Y_i-\bar Y_i=Y_i-(\bar \beta_0+\bar \beta_1X_{1i}+\bar \beta_2X_{2i}+…+\bar \beta_kX_{ki})<br> $$</p>
<p>由最小二乘法可知 $\bar \beta_0,\bar \beta_2,\bar \beta_2,..\bar \beta_k$ 应使全部观测值$Y_i$ 与回归值 $\bar Y_i$ 的残差 $e_i$ 的平方和最小，即使</p>
<p>$$<br>  Q(\bar \beta_0,\bar \beta_2,\bar \beta_2,..\bar \beta_k)=\sum e^2_i=\sum(Y-\bar Y_i)^2\<br>  =\sum(Y_i-\bar \beta <em>0-\bar \beta_1X</em>{1i}-\bar \beta_2X_{2i}-…\bar \beta_kX_{ki})<br>$$</p>
<p>取得最小值。令 $Y=(Y_i,Y_1,Y_2,..Y_n),X=(x_0,x_1,…x_n),\bar B=(\bar \beta_0,\bar \beta_2,\bar \beta_2,..\bar \beta_k)$  ,上式可写为</p>
<p>$$<br>Q((\bar \beta_0,\bar \beta_2,\bar \beta_2,..\bar \beta_k)=(Y-\bar BX)^T(Y-\bar BX)\<br>=(Y^TY-Y^TX\bar B-\bar BX^TY+\bar B^TX^TX\bar B)\<br>=Y^TY-2\bar B^TX^TY+\bar B^TX^TX\bar B<br>$$</p>
<p>根据多元函数的极值原理，$Q$ 分别对 $\bar \beta_0,\bar \beta_2,\bar \beta_2,..\bar \beta_k$ 求一阶偏导，并令其等于零，即</p>
<p>$$<br> \frac{\partial Q}{\partial \bar \beta _j}=0(j=0,1,2…k)<br>$$</p>
<p>即 $-X^TY+X^TX\bar B=0$ 。则为向量 $B$ 的估计量为</p>
<p>$$<br>  \bar B= (X^TX)^{-1}X^TY<br>$$</p>
<h2 id="几何概率"><a href="#几何概率" class="headerlink" title="几何概率"></a>几何概率</h2><p>  几何概率(<em>geometric probability</em>)可以用几何方法向某一可度量的区域求得的概率。向区域内投一质点，如果所投的点落在域<em>O</em>中任意区域<em>g</em>内的可能性大小与<em>g</em>的度量成正比，而与<em>g</em>的具体形状无关，则称这个随机试验为几何型随机试验或几何概率。此处的度量就是测度，一维是长度，二维是面积，三维是体积。对于几何概率，若记 $A = 质点落在区域g内$ 这一事件，则其概率定义为</p>
<p>  $$<br>    P(A) = \frac{L(g)}{L(\Omega)}<br>  $$</p>
<p> 其中 $L(g)$ 和 $L(\Omega)$ 分别为<em>g</em>和<em>O</em>的度量。这一类概率是古典概率定义的推广，它保留了等可能性，但将有限个基本事件推广到了无限。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-10-01-regular-attachment/" data-id="ck4ifp1lv001l2wjef9hxf4q8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-09-26-pyspark-moiverecommand" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-09-26-pyspark-moiverecommand/" class="article-date">
  <time datetime="2019-12-23T10:45:59.340Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-09-26-pyspark-moiverecommand/">使用pyspark做数据挖掘</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一-环境准备"><a href="#一-环境准备" class="headerlink" title="一 环境准备"></a>一 环境准备</h2><h3 id="1-1-编程环境"><a href="#1-1-编程环境" class="headerlink" title="1.1 编程环境"></a>1.1 编程环境</h3><pre><code>必须加入spark内容，将以下代码加入推荐逻辑之前   </code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Path for spark source folder</span><br><span class="line">os.environ[&#39;SPARK_HOME&#39;]&#x3D;&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6&quot;</span><br><span class="line"># Append pyspark  to Python Path</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python&quot;)</span><br><span class="line">sys.path.append(&quot;D:\javaPackages\spark-1.6.0-bin-hadoop2.6\python\lib\py4j-0.9-src.zip&quot;)</span><br><span class="line">from pyspark import SparkContext</span><br><span class="line">from pyspark import SparkConf</span><br><span class="line">conf &#x3D; SparkConf()</span><br><span class="line">conf.set(&quot;YARN_CONF_DIR &quot;, &quot;D:\javaPackages\hadoop_conf_dir\yarn-conf&quot;)</span><br><span class="line">conf.set(&quot;spark.driver.memory&quot;, &quot;2g&quot;)</span><br></pre></td></tr></table></figure>

<p>各个参数视个人机器配置而定</p>
<h3 id="1-2-本地模式"><a href="#1-2-本地模式" class="headerlink" title="1.2  本地模式"></a>1.2  本地模式</h3><pre><code>在本地模式运行时，参数需要如下设定</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conf.setMaster(&quot;client&quot;)</span><br><span class="line">此时代码会在本地执行，对于小数据集（小于1MB的数据）可以正常执行，如果数据超过1MB将会遇到以下问题：</span><br><span class="line">ERROR PythonRDD: Python worker exited unexpectedly (crashed)</span><br><span class="line">java.net.SocketException: Connection reset by peer: socket write error</span><br><span class="line">        at java.net.SocketOutputStream.socketWrite0(Native Method)</span><br><span class="line">解决办法参考“pyspark处理大数据集” 这篇笔记</span><br></pre></td></tr></table></figure>

<h3 id="1-3-数据准备"><a href="#1-3-数据准备" class="headerlink" title="1. 3 数据准备"></a>1. 3 数据准备</h3><pre><code>数据都是存放在HDFS上，需要先将数据上传到个人目录。</code></pre><h2 id="二-数据挖掘视角"><a href="#二-数据挖掘视角" class="headerlink" title="二 数据挖掘视角"></a>二 数据挖掘视角</h2><pre><code>接下来进入数据挖掘的思路，数据挖掘标准流程如下：</code></pre><ul>
<li><p>数据收集（本案例中数据已经准备好）</p>
</li>
<li><p>数据清洗转换</p>
</li>
<li><p>根据数据选择算法模型（本案例以推荐算法为例）</p>
</li>
<li><p>训练模型：使用训练数据训练算法模型中一些参数。</p>
</li>
<li><p>使用模型：使用训练好的模型预测或者对检验数据分类、聚类</p>
</li>
<li><p>评估模型：验证模型预测结果与真实结果误差，评估准确率、召回率等指标</p>
</li>
</ul>
<h3 id="2-1-收集数据"><a href="#2-1-收集数据" class="headerlink" title="2.1 收集数据"></a>2.1 收集数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset_path &#x3D; os.path.join(&#39;&#x2F;home&#x2F;xiatao&#x2F;machine_learing&#x2F;moive_recommend&#x2F;&#39;,&#39;&#39;)</span><br><span class="line">complete_dataset_path &#x3D;   os.path.join(dataset_path,&#39;ml-latest.zip&#39;)</span><br><span class="line">small_dataset_path &#x3D; os.path.join(dataset_path,&#39;ml-latest-small.zip&#39;)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-数据清洗转换"><a href="#2-2-数据清洗转换" class="headerlink" title="2.2 数据清洗转换"></a>2.2 数据清洗转换</h3><p>   本示例中数据清洗和转换比较简单，只是去掉数据头，并将数据封装成RDD。在其他数据中可能需要去除部分没用的列，数据降维，连续型数据转换为离散型等操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 载入数据，将数据的头过滤出来</span><br><span class="line">small_rating_file &#x3D; os.path.join(dataset_path,&#39;latest_small&#39;,&#39;ratings.csv&#39;)</span><br><span class="line">small_rating_raw_data &#x3D; sc.textFile(small_rating_file)</span><br><span class="line">small_rating_raw_data_header &#x3D; small_rating_raw_data.take(1)[0]</span><br><span class="line"># 将原始数据封装成新的RDD</span><br><span class="line">small_rating_data  &#x3D; small_rating_raw_data.filter(lambda line:line!&#x3D;small_rating_raw_data_header)\</span><br><span class="line">    .map(lambda line:line.split(&quot;,&quot;)).map(lambda tokens:(tokens[0],tokens[1],tokens[2])).cache()</span><br></pre></td></tr></table></figure>

<h3 id="2-3-根据数据选择算法模型"><a href="#2-3-根据数据选择算法模型" class="headerlink" title="2.3 根据数据选择算法模型"></a>2.3 根据数据选择算法模型</h3><pre><code>本示例以推荐算法中的ALS（最小交替二乘法）为例，关于交替二乘法参考 https://www.zhihu.com/question/31509438</code></pre><h3 id="2-4-训练模型"><a href="#2-4-训练模型" class="headerlink" title="2.4  训练模型"></a>2.4  训练模型</h3><pre><code>在开始之前，我们先将数据分为三份，分别是training_rdd（训练数据） ,validation_rdd（验证数据）,test_rdd（测试数据）。使用training_rdd获得一个训练模型，然后去预测validation_rdd结果，并计算训练模型对validation_rdd预测结果与validation_rdd真实结果之间误差，以此来决定模型应该使用的参数。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用小数据集选择 交叉最小二乘法参数</span><br><span class="line"># 首先将数据分为训练数据，校验数据，测试数据</span><br><span class="line">training_rdd ,validation_rdd,test_rdd &#x3D; small_rating_data.randomSplit([6,2,2],seed&#x3D;0L)</span><br><span class="line">validation_for_predict_rdd &#x3D; validation_rdd.map(lambda x:(x[0],x[1]))</span><br><span class="line">test_for_predict_rdd &#x3D;test_rdd.map(lambda x:(x[0],x[1]))</span><br></pre></td></tr></table></figure>

<p> 推荐算法ALS中最重要的比较重要的参数有如下：</p>
<ul>
<li><p>rank：特征向量秩大小，越大的秩会得到更好的模型，但是计算消耗也相应增加。默认是 10</p>
</li>
<li><p>iteration： 算法迭代次数（默认是10）</p>
</li>
<li><p>lambda：正则参数，默认是 0.01。详细解释参考</p>
</li>
<li><p>alpha：在隐式ALS中用于计算置信度的常量，默认为1.0</p>
</li>
<li><p>numUserBlocks,numProductBlocks：将用户和产品数据分解的块数目，用来控制并行度；你可以传入-1来让MLlib自动决定。</p>
<p>   本示例中，算法迭代次数固定为10（可以根据实际情况调整），lambda参数固定位 0.1 ，由于本文的电影评分数据是确信数据，使用的ALS是确定模型，因此不需要alpha参数，numUserBlocks和numProductBlocks参数使用默认参数。<br>  因此，本示例中需要训练的参数是 rank，不同的rank会影响模型的预测准确度，不同的模型其预测误差可以通过均方根误差（标准方差RMSE）来衡量优劣。选取均方根误差最小的rank作为预测模型的rank。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">seed &#x3D;5L</span><br><span class="line">iterations &#x3D;10</span><br><span class="line">regularization_parmeter &#x3D;0.1</span><br><span class="line">ranks &#x3D;[4,5,6,7,8,10,12]</span><br><span class="line">errors &#x3D; [0,0,0,0,0,0,0]</span><br><span class="line">err &#x3D;0</span><br><span class="line">min_error &#x3D; float(&#39;inf&#39;)</span><br><span class="line">best_rank &#x3D;-1</span><br><span class="line">best_interation &#x3D;-1</span><br><span class="line">for rank in ranks:</span><br><span class="line">    model &#x3D; ALS.train(training_rdd,rank,seed&#x3D;seed,iterations&#x3D;iterations,lambda_&#x3D;regularization_parmeter)</span><br><span class="line">    predictions &#x3D; model.predictAll(validation_for_predict_rdd).map(lambda r:((r[0],r[1],r[2])))</span><br><span class="line">    rates_and_preds &#x3D;validation_rdd.map(lambda r:(int(r[0]),int(r[1]),float(r[2]))).join(predictions)</span><br><span class="line">    error &#x3D; math.sqrt(rates_and_preds.map(lambda r:(r[1][0]-r[1][1])**2).mean())</span><br><span class="line">    errors[err] &#x3D; error</span><br><span class="line">    err+&#x3D;1</span><br><span class="line">    print &#39;For rank %s the RMSE is %s&#39;%(rank,error)</span><br><span class="line">    if error &lt; min_error:</span><br><span class="line">        min_error &#x3D;error</span><br><span class="line">        best_rank &#x3D; rank</span><br></pre></td></tr></table></figure>

<h2 id="2-5-使用模型"><a href="#2-5-使用模型" class="headerlink" title="2.5 使用模型"></a>2.5 使用模型</h2><pre><code>使用训练数据中获得的最佳参数来构建新的推荐模型，本示例中使用完整数据集ml-lates数据集检验模型预测结果,为了检验模型准确率，我们将数据分为训练数据和验证数据两份，分别为training_complete_rdd(70%),test_complete_rdd (30%)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#现在开始使用完整数据集来构建最终模型</span><br><span class="line">complete_rating_file &#x3D; os.path.join(dataset_path,&#39;latest_all&#39;,&#39;ratings.csv&#39;)</span><br><span class="line">complete_rating_raw_data &#x3D;sc.textFile(complete_rating_file)</span><br><span class="line">complete_rating_raw_data_header &#x3D; complete_rating_raw_data.take(1)[0]</span><br><span class="line">complete_rating_data &#x3D; complete_rating_raw_data.filter(lambda line:line!&#x3D;complete_rating_raw_data_header)\</span><br><span class="line">    .map(lambda line:line.split(&quot;,&quot;)).map(lambda tokens:(int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()</span><br><span class="line">#现在开始训练推荐模型</span><br><span class="line">training_complete_rdd,test_complete_rdd &#x3D; complete_rating_data.randomSplit([7,3],seed &#x3D;0L)</span><br><span class="line">complete_model &#x3D; ALS.train(training_complete_rdd,best_rank,seed &#x3D; seed,iterations&#x3D;\</span><br><span class="line">    iterations,lambda_ &#x3D;regularization_parmeter)</span><br></pre></td></tr></table></figure>

<h3 id="2-6-评估验证模型"><a href="#2-6-评估验证模型" class="headerlink" title="2.6 评估验证模型"></a>2.6 评估验证模型</h3><pre><code>使用完整数据集中30%的部分来测试模型预测结果准确率。 </code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#在测试数据集上测试</span><br><span class="line">test_for_predict_rdd &#x3D; test_complete_rdd.map(lambda x:(x[0],x[1]))</span><br><span class="line">predictions_complete &#x3D;complete_model.predictAll(test_for_predict_rdd).map(lambda r:((r[0],r[1],r[2])))</span><br><span class="line">rates_and_preds_complete &#x3D; test_complete_rdd.map(lambda r:((int(r[0]),int(r[1])),float(r[2]))).join(predictions_complete)</span><br><span class="line">error_complete &#x3D; math.sqrt(rates_and_preds_complete.map(lambda r: (r[1][0]-r[1][1]) **2).mean())</span><br><span class="line">mylog.append( &quot;完整数据集的误差是RMSE   %s&quot;%(error_complete))</span><br></pre></td></tr></table></figure>

<pre><code>此示例中只使用了平方根误差来评估模型。</code></pre><h3 id="2-7-模型后续使用"><a href="#2-7-模型后续使用" class="headerlink" title="2.7 模型后续使用"></a>2.7 模型后续使用</h3><h4 id="2-7-1-给老用户（对部分电影有评分）推荐"><a href="#2-7-1-给老用户（对部分电影有评分）推荐" class="headerlink" title="2.7.1 给老用户（对部分电影有评分）推荐"></a>2.7.1 给老用户（对部分电影有评分）推荐</h4><pre><code>添加新数据，每次添加新数据都需要重新训练模型，此时将新数据与原数据合并再训练并得到模型。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#添加新的用户评分，</span><br><span class="line">new_user_ID &#x3D; 0</span><br><span class="line">new_user_rating &#x3D;[</span><br><span class="line">    (0,260,9),</span><br><span class="line">    (0,1,8),</span><br><span class="line">    (0,16,7),</span><br><span class="line">    (0,25,8),</span><br><span class="line">    (0,32,9),</span><br><span class="line">    (0,335,4),</span><br><span class="line">    (0,379,4),</span><br><span class="line">    (0,296,4),</span><br><span class="line">    (0,854,10),</span><br><span class="line">    (0,50,8)</span><br><span class="line">]</span><br><span class="line">new_user_rating_RDD &#x3D; sc.parallelize(new_user_rating)</span><br><span class="line">mylog.append( &quot;新用户的评分是 %s&quot;%new_user_rating_RDD.take(10))</span><br><span class="line"># 将数据加入到推荐模型将使用的训练数据中，</span><br><span class="line">complete_data_with_new_rating_RDD &#x3D; complete_rating_data.union(new_user_rating_RDD)</span><br><span class="line"># 最后，使用前面选择的最优参数来训练ALS模型</span><br><span class="line">from time import time</span><br><span class="line">new_rating_model &#x3D; ALS.train(complete_data_with_new_rating_RDD,best_rank,seed &#x3D; seed,iterations&#x3D;iterations,lambda_ &#x3D;regularization_parmeter)</span><br></pre></td></tr></table></figure>

<p>再利用此模型向老用户推荐电影   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 获取最好的推荐。鉴于我们将获得新用户没有评分的RDD</span><br><span class="line">#获得电影ID</span><br><span class="line">new_users_ratings_ids &#x3D; map(lambda x:x[1],new_user_rating)</span><br><span class="line">#获得不在ID列表中的</span><br><span class="line">new_user_unrated_moive_RDD &#x3D; (complete_moive_data.filter(lambda x:x[0] not in new_users_ratings_ids)\</span><br><span class="line">                              .map(lambda x:(new_user_ID,x[0])))</span><br><span class="line"># 使用输入的RDD和 new_user_unrated_moive_RDD，使用 new_rating_mode.predictAll() 来预测电影</span><br><span class="line">new_user_recommendations_RDD &#x3D; new_rating_model.predictAll(new_user_unrated_moive_RDD)</span><br><span class="line">new_user_recommendations_rating_RDD &#x3D; new_user_recommendations_RDD.map(lambda x:(x.product,x.rating))</span><br><span class="line">new_user_recommendations_rating_title_and_count_RDD &#x3D;new_user_recommendations_rating_RDD.join(complete_moive_titles)\</span><br><span class="line">    .join(moive_rating_counts_RDD)</span><br><span class="line">new_user_recommendations_rating_title_and_count_RDD.take(3)</span><br><span class="line">top_moives &#x3D; new_user_recommendations_rating_title_and_count_RDD.map(lambda r:(r[1][0][1],r[1][0][0],r[1][1]))\</span><br><span class="line">    .filter(lambda r:r[2]&gt;&#x3D;25).takeOrdered(25,key&#x3D;lambda x:-x[1])</span><br><span class="line">mylog.append( &quot;推荐的电影（浏览量超过25的）%s&quot;%&#39;\n&#39;.join(map(str,top_moives)))</span><br></pre></td></tr></table></figure>

<h4 id="2-7-2-预测新用户对某部电影评分"><a href="#2-7-2-预测新用户对某部电影评分" class="headerlink" title="2.7.2  预测新用户对某部电影评分"></a>2.7.2  预测新用户对某部电影评分</h4><h2 id="三-模型的保存于复用"><a href="#三-模型的保存于复用" class="headerlink" title="三  模型的保存于复用"></a>三  模型的保存于复用</h2><pre><code>可以将我们的模型存储起来作为后续的在线推荐系统使用，尽管每次有新的用户评分数据时都会生成新的模型，为了节省服务启动时间。当前的模型也是值得存储的。我们可以通过存储那些RDD以节省时间，尤其是那些需要消耗极大时间的。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.mllib.recommendation import MatrixFactorizationModel</span><br><span class="line">model_path &#x3D; os.path.join(dataset_path,&#39;models&#39;,&#39;moive_lens_als&#39;)</span><br><span class="line">model.save(sc,model_path)</span><br><span class="line">same_model &#x3D; MatrixFactorizationModel.load(sc,model_path)</span><br></pre></td></tr></table></figure>






      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-09-26-pyspark-moiverecommand/" data-id="ck4ifp1lu001j2wjeb9au4n63" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2016-09-25-sparkmllib" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-09-25-sparkmllib/" class="article-date">
  <time datetime="2019-12-23T10:45:59.339Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/23/2016-09-25-sparkmllib/">大数据：spark mllib集成学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>此文可以参考<a href="http://blog.jobbole.com/85408/" target="_blank" rel="noopener">如何在MLlib中实现随机森林和梯度提升树（GBTs）</a>一起阅读</p>
<h1 id="一-梯度提升树和随机森林"><a href="#一-梯度提升树和随机森林" class="headerlink" title="一  梯度提升树和随机森林"></a>一  梯度提升树和随机森林</h1><p>&emsp;&emsp;梯度提升树(Gradient-Boosted Trees，GBTs)和随机森林都是决策树的集成学习方法，但是训练过程不一。以下是两种之间的一些利弊：</p>
<ul>
<li>GBTs一次训练一颗树，所以它会比随机森林耗时更长。随机森林可以并行训练多颗树。<ul>
<li>另一方面，给GBTs使用比随机森林更小的树比较合理，训练更小的树耗时更少。</li>
</ul>
</li>
<li>随机森林更不易过拟合。训练更多的决策树可以减少随机森林过拟合风险，但会增加GBTs过拟合风险。</li>
<li>由于增加随机森林使用的决策树数目可以单调的提升性能，因而森林更容易调节。但对于GBTs，决策树数目过大时可能会导致性能的减弱。</li>
</ul>
<h1 id="二-随机森林"><a href="#二-随机森林" class="headerlink" title="二 随机森林"></a>二 随机森林</h1><p>在分类和回归中，随机森林是最成功的机器学习方法。它结合多颗决策树以减少过拟合风险。比如决策树，随机森林可以处理类别特征，如果不需要数据规范化（关于数据规范化，可以参考<a href="http://blog.csdn.net/memray/article/details/9023737" target="_blank" rel="noopener">数据规范化</a>,数据规范化的好处参考<br><a href="https://www.zhihu.com/question/37129350/answer/70964527" target="_blank" rel="noopener">为什么feature scaling会使 gradient desent收敛更好</a>）的话可以拓展到多分类，并且可以处理非线性和特征交互问题。<br><strong>spark.mllib</strong> 可以同时使用连续型数据和类别特征，为分类和逻辑回归提供二分类和多分类。直接使用了现有的决策树实现了随机森林。</p>
<h2 id="2-1-基本算法"><a href="#2-1-基本算法" class="headerlink" title="2.1 基本算法"></a>2.1 基本算法</h2><p>随机森林单独的训练集合中每一课决策树，因而可以并行执行。算法在训练过程中引入了随机性，使得每个决策树都不一样。结合每棵树的决策可以减少最终决策偏差，提高算法最终表现。</p>
<h2 id="2-2-训练数据"><a href="#2-2-训练数据" class="headerlink" title="2.2 训练数据"></a>2.2 训练数据</h2><p>随机森林算法中加入的随机性包括以下：</p>
<ul>
<li>每次迭代时从原始数据集中抽样部分数据，以保证每次的数据不同。</li>
<li>每次切分树节点时会考虑特征的随机子集。</li>
</ul>
<h2 id="2-3-预测"><a href="#2-3-预测" class="headerlink" title="2.3 预测"></a>2.3 预测</h2><p>&emsp;&emsp;为了在新数据上作出预测，随机森林需要从其决策树集合中合计出预测，这个过程在分类和回归中是完全不同的。</p>
<ul>
<li>分类：多数表决，每棵树的预测都会为某一个分类投一票，得票最多的分类即预测分类。</li>
<li>回归： 平均主义，每棵树预测值是一个实数，预测的分类为所有预测值的均值。</li>
</ul>
<h2 id="2-4-小提示"><a href="#2-4-小提示" class="headerlink" title="2.4 小提示"></a>2.4 小提示</h2><p>&emsp;&emsp;以下两个参数微调可以提高算法性能</p>
<ul>
<li><strong>numTrees</strong>:森林中的决策树数目。<ul>
<li>增加数数目可以减少预测偏差，提高模型的测试时间准确率。</li>
<li>训练时长会随着树数目增加而大致线性增长</li>
</ul>
</li>
<li><strong>maxDepth</strong>:森林中每棵树的最大深度<ul>
<li>增加深度会更强大的模型，同时会增加消耗。但是更深的树，训练时间更长，同时更容易产生过拟合问题。</li>
<li>通常来说，与单一决策树相比，随机森林总更适合训练更深的树。单一决策树更容易产生过拟合问题。</li>
</ul>
</li>
</ul>
<p>&emsp;&emsp;以下连个参数通常不需要调节，但是可以用来加速训练过程</p>
<ul>
<li><strong>subsample</strong>: 此参数用来设置随机森林中每棵树训练时使用的数据集大小，值为原始数据集比例。推荐默认值1.0，但是减少此值可以加速训练过程。</li>
<li><strong>featureSubsetStraegy</strong>: 每个树节点分裂候选的特征数。该值设置为分数或者关于总特征数的函数。减少此值可以加速训练过程，但是太低的话可能会影响性能。</li>
</ul>
<h2 id="2-5-代码示例"><a href="#2-5-代码示例" class="headerlink" title="2.5 代码示例"></a>2.5 代码示例</h2><p>以下代码演示了如何载入 <strong>LIBSVM data file</strong> ，将其解析成<strong>LabeledPoint</strong>类型的RDD，然后使用随机森林来分类。使用测试误差来衡量算法准确率</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-09-25-sparkmllib/" data-id="ck4ifp1lt001h2wje2yoee9bj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/6/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/8/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/23/template/">博客题目</a>
          </li>
        
          <li>
            <a href="/2019/12/23/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-11-26-model-pruning/">模型剪枝和优化-torch和Tensorflow为例</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-10-28--understand-pytorch/">理解pytorch的计算逻辑</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-09-24-outlier-detection/">使用pyod做离群点检测</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 shartoo<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>