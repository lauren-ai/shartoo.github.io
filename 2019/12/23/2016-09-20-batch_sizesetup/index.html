<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>深度学习：batch_size的设置与影响 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="神经网络基础">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习：batch_size的设置与影响">
<meta property="og:url" content="http://shartoo.github.com/2019/12/23/2016-09-20-batch_sizesetup/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="神经网络基础">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://shartoo.github.com/images/blog/batch_size1.png">
<meta property="og:image" content="http://shartoo.github.com/images/blog/batch_size2.png">
<meta property="article:published_time" content="2019-12-23T10:45:59.334Z">
<meta property="article:modified_time" content="2019-12-23T09:55:14.200Z">
<meta property="article:author" content="shartoo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://shartoo.github.com/images/blog/batch_size1.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shartoo.github.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-2016-09-20-batch_sizesetup" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-09-20-batch_sizesetup/" class="article-date">
  <time datetime="2019-12-23T10:45:59.334Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      深度学习：batch_size的设置与影响
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>注意：本文根据知乎<strong>程引</strong>的<a href="https://www.zhihu.com/question/32673260" target="_blank" rel="noopener">回答</a>整理</p>
<h2 id="为何需要batch-size参数"><a href="#为何需要batch-size参数" class="headerlink" title="为何需要batch_size参数"></a>为何需要batch_size参数</h2><p> Batch的选择，<strong>首先决定的是下降的方向</strong>。如果数据集比较小，完全可以采用 <strong>全数据集(Full Batch Learning)</strong> 的形式。这样做有如下好处：</p>
<ul>
<li><p>全数据集确定的方向能够更好的代表样本总体，从而更准确的朝着极值所在方向。</p>
</li>
<li><p>由于不同权值的梯度值差别较大，因此选取一个全局的学习率很困难。</p>
<p>Full Batch Learning可以使用Rprop只基于梯度符号并且针对性单独更新各权值。<br>但是对于非常大的数据集，上述两个好处变成了两个坏处：</p>
</li>
<li><p>随着数据集的海量增加和内存限制，一次载入所有数据不现实。</p>
</li>
<li><p>以Rprop的方式迭代，会由于各个batch之间的采样差异性，各此梯度修正值相互抵消，无法修正。这才有了后来的<strong>RMSprop</strong>的妥协方案。</p>
</li>
</ul>
<h2 id="Full-Batch-Learning的另一个极端-Online-Learning"><a href="#Full-Batch-Learning的另一个极端-Online-Learning" class="headerlink" title="Full Batch Learning的另一个极端 Online Learning"></a>Full Batch Learning的另一个极端 Online Learning</h2><p> 既然 Full Batch Learning 并不适用大数据集，那么走向另一个极端怎么样？所谓另一个极端，就是每次只训练一个样本，即 Batch_Size = 1。这就是<strong>在线学习(Online Learning)</strong> 。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。使用在线学习，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，<strong>难以达到收敛</strong></p>
<p> <img src="/images/blog/batch_size1.png" alt="batch_size"></p>
<h2 id="选取适中的batch-size"><a href="#选取适中的batch-size" class="headerlink" title="选取适中的batch_size"></a>选取适中的batch_size</h2><p>  可不可以选择一个适中的 Batch_Size 值呢？当然可以，这就是<strong>批梯度下降法（Mini-batches Learning）</strong>。因为如果数据集足够充分，那么用一半（<em>甚至少得多</em>）的数据训练算出来的梯度与用全部数据训练出来的梯度是<strong>几乎一样</strong>的。<br>  在合理范围内，增大 Batch_Size 有何好处？</p>
<ul>
<li><p>内存利用率提高了，大矩阵乘法的并行化效率提高。</p>
</li>
<li><p>跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</p>
</li>
<li><p>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</p>
<p>盲目增大 Batch_Size 有何<u>坏处</p>
</li>
<li><p>内存利用率提高了，但是内存容量可能撑不住了。</p>
</li>
<li><p>跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</p>
</li>
<li><p>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</p>
</li>
</ul>
<h2 id="调节-Batch-Size-对训练效果影响到底如何？"><a href="#调节-Batch-Size-对训练效果影响到底如何？" class="headerlink" title="调节 Batch_Size 对训练效果影响到底如何？"></a>调节 Batch_Size 对训练效果影响到底如何？</h2><p>  这里跑一个 LeNet 在 MNIST 数据集上的效果。MNIST 是一个手写体标准库</p>
<p>   <img src="/images/blog/batch_size2.png" alt="batch_size"></p>
<p>  运行结果如上图所示，其中绝对时间做了标准化处理。运行结果与上文分析相印证：</p>
<ul>
<li>Batch_Size 太小，算法在 200 epoches 内不收敛。</li>
<li>随着 Batch_Size 增大，处理相同数据量的速度越快。</li>
<li>随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。</li>
<li>由于上述两种因素的矛盾， Batch_Size 增大到<u>某个</u>时候，达到<b>时间上</b>的最优。</li>
<li>由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到<u>某些</u>时候，达到最终收敛<strong>精度上</strong>的最优。</li>
</ul>
<h2 id="caffe中batch-size影响"><a href="#caffe中batch-size影响" class="headerlink" title="caffe中batch size影响"></a>caffe中batch size影响</h2><p> caffe的代码实现上选取一个batch的时候似乎是按着数据库的图片顺序选取输入图片的，所以在生成数据库的时候切记要shuffle一下图片顺序。caffe中完成这一步的代码为</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$caffe_root&#x2F;build&#x2F;tools&#x2F;convert_imageset -shuffle -resize_height&#x3D;256 -resize_width&#x3D;256</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-09-20-batch_sizesetup/" data-id="ck4ifp1lr001b2wje4x1sc0rz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/12/23/2016-09-20-pyspark-mllibuse/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          pyspark机器学习库使用
        
      </div>
    </a>
  
  
    <a href="/2019/12/23/2016-09-09-tensorflow-retainmodel/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">tensorflow：如何重新训练Inception模型的最后一层，以应对新分类</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/23/template/">博客题目</a>
          </li>
        
          <li>
            <a href="/2019/12/23/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-11-26-model-pruning/">模型剪枝和优化-torch和Tensorflow为例</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-10-28--understand-pytorch/">理解pytorch的计算逻辑</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-09-24-outlier-detection/">使用pyod做离群点检测</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 shartoo<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>