<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>大数据：kafka常见问题 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="大数据专题">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据：kafka常见问题">
<meta property="og:url" content="http://shartoo.github.com/2019/12/23/2016-03-10-kafkaquestion/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="大数据专题">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://shartoo.github.com/images/blog/kafka-question1.jpg">
<meta property="og:image" content="http://shartoo.github.com/images/blog/kafka-question2.jpg">
<meta property="article:published_time" content="2019-12-23T10:45:59.292Z">
<meta property="article:modified_time" content="2019-12-23T09:55:14.195Z">
<meta property="article:author" content="shartoo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://shartoo.github.com/images/blog/kafka-question1.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shartoo.github.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-2016-03-10-kafkaquestion" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/12/23/2016-03-10-kafkaquestion/" class="article-date">
  <time datetime="2019-12-23T10:45:59.292Z" itemprop="datePublished">2019-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/blog/">blog</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      大数据：kafka常见问题
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一-kafka如何处理消费过的数据"><a href="#一-kafka如何处理消费过的数据" class="headerlink" title="一 kafka如何处理消费过的数据"></a>一 kafka如何处理消费过的数据</h1><h2 id="1-1-如果想消费已经被消费过的数据"><a href="#1-1-如果想消费已经被消费过的数据" class="headerlink" title="1.1     如果想消费已经被消费过的数据"></a>1.1     如果想消费已经被消费过的数据</h2><ul>
<li><p>consumer是底层采用的是一个阻塞队列，只要一有producer生产数据，那consumer就会将数据消费。当然这里会产生一个很严重的问题，如果你重启一消费者程序，那你连一条数据都抓不到，但是log文件中明明可以看到所有数据都好好的存在。换句话说，一旦你消费过这些数据，那你就无法再次用同一个groupid消费同一组数据了。    </p>
</li>
<li><p><strong>原因:</strong> 消费者消费了数据并不从队列中移除，只是记录了offset偏移量。同一个consumer group的所有consumer合起来消费一个topic，并且他们每次消费的时候都会保存一个offset参数在zookeeper的root上。如果此时某个consumer挂了或者新增一个consumer进程，将会触发kafka的负载均衡，暂时性的重启所有consumer，重新分配哪个consumer去消费哪个partition，然后再继续通过保存在zookeeper上的offset参数继续读取数据。注意:offset保存的是consumer 组消费的消息偏移。    </p>
</li>
<li><p>如何消费同一组数据：</p>
<ol>
<li>采用不同的group</li>
<li>通过一些配置，就可以将线上产生的数据同步到镜像中去，然后再由特定的集群区处理大批量的数据。详见<a href="http://my.oschina.net/ielts0909/blog/110280" target="_blank" rel="noopener">详细</a><br><img src="/images/blog/kafka-question1.jpg" alt="图片"></li>
</ol>
</li>
</ul>
<h2 id="1-2-如何自定义去消费已经消费过的数据"><a href="#1-2-如何自定义去消费已经消费过的数据" class="headerlink" title="1.2    如何自定义去消费已经消费过的数据"></a>1.2    如何自定义去消费已经消费过的数据</h2><h3 id="1-2-1-Conosumer-properties配置文件中有两个重要参数"><a href="#1-2-1-Conosumer-properties配置文件中有两个重要参数" class="headerlink" title="1.2.1 Conosumer.properties配置文件中有两个重要参数:"></a>1.2.1 Conosumer.properties配置文件中有两个重要参数:</h3><ul>
<li><strong>auto.commit.enable</strong>:如果为true，则consumer的消费偏移offset会被记录到zookeeper。下次consumer启动时会从此位置继续消费。</li>
<li><strong>auto.offset.reset</strong>: 该参数只接受两个常量largest和Smallest,分别表示将当前offset指到日志文件的最开始位置和最近的位置。<br>如果进一步想控制时间，则需要调用Simple Consumer，自己去设置相关参数。比较重要的参数是 kafka.api.OffsetRequest.EarliestTime()和kafka.api.OffsetRequest.LatestTime()分别表示从日志（数据）的开始位置读取和只读取最新日志。    </li>
</ul>
<h3 id="1-2-2-如何使用SimpleConsumer"><a href="#1-2-2-如何使用SimpleConsumer" class="headerlink" title="1.2.2 如何使用SimpleConsumer"></a>1.2.2 如何使用SimpleConsumer</h3><ul>
<li><p>首先，你必须知道读哪个topic的哪个partition<br>然后，找到负责该partition的broker leader，从而找到存有该partition副本的那个broker    </p>
</li>
<li><p>再者，自己去写request并fetch数据.      </p>
</li>
<li><p>最终，还要注意需要识别和处理broker leader的改变.    </p>
<p><a href="http://stackoverflow.com/questions/14935755/how-to-get-data-from-old-offset-point-in-kafka" target="_blank" rel="noopener">参考1</a><br><a href="https://cwiki.apache.org/confluence/display/KAFKA/Committing+and+fetching+consumer+offsets+in+Kafka" target="_blank" rel="noopener">参考2</a><br><a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example" target="_blank" rel="noopener">完整代码</a>        </p>
</li>
</ul>
<h2 id="2-kafka-partition和consumer数目关系"><a href="#2-kafka-partition和consumer数目关系" class="headerlink" title="2    kafka partition和consumer数目关系"></a>2    kafka partition和consumer数目关系</h2><ol>
<li><p>如果consumer比partition多，是浪费，因为kafka的设计是在一个partition上是不允许并发的，所以consumer数不要大于partition数 。</p>
</li>
<li><p>如果consumer比partition少，一个consumer会对应于多个partitions，这里主要合理分配consumer数和partition数，否则会导致partition里面的数据被取的不均匀 。最好partiton数目是consumer数目的整数倍，所以partition数目很重要，比如取24，就很容易设定consumer数目 。</p>
</li>
<li><p>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同 </p>
</li>
<li><p>增减consumer，broker，partition会导致rebalance，所以rebalance后consumer对应的partition会发生变化    </p>
<p><a href="http://www.cnblogs.com/fxjwind/p/3794255.html" target="_blank" rel="noopener">详见</a>     </p>
</li>
</ol>
<h2 id="3-kafka副本问题"><a href="#3-kafka副本问题" class="headerlink" title="3    kafka副本问题"></a>3    kafka副本问题</h2><p>   kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。    </p>
<h2 id="3-1-如何分配副本"><a href="#3-1-如何分配副本" class="headerlink" title="3.1     如何分配副本"></a>3.1     如何分配副本</h2><p>   Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致.    </p>
<h2 id="3-2-Kafka分配Replica的算法如下"><a href="#3-2-Kafka分配Replica的算法如下" class="headerlink" title="3.2 Kafka分配Replica的算法如下"></a>3.2 Kafka分配Replica的算法如下</h2><p>   1.将所有Broker（假设共n个Broker）和待分配的Partition排序.<br>   2. 将第i个Partition分配到第（i mod n）个Broker上.<br>   3. 将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上.</p>
<p>   <a href="http://www.haokoo.com/internet/2877400.html" target="_blank" rel="noopener">算法详细</a>    </p>
<h2 id="4-kafka如何设置生存周期与清理数据"><a href="#4-kafka如何设置生存周期与清理数据" class="headerlink" title="4    kafka如何设置生存周期与清理数据"></a>4    kafka如何设置生存周期与清理数据</h2><p>   日志文件的删除策略非常简单:启动一个后台线程定期扫描log file列表,把保存时间超过阀值的文件直接删除(根据文件的创建时间).清理参数在server.properties文件中：<br>  <img src="/images/blog/kafka-question2.jpg" alt=""><br>  <a href="http://blog.csdn.net/lizhitao/article/details/25667831" target="_blank" rel="noopener">详见</a>或<a href="http://kafka.apache.org/documentation.html" target="_blank" rel="noopener">官网说明</a>    </p>
<h2 id="5-zookeeper如何管理kafka"><a href="#5-zookeeper如何管理kafka" class="headerlink" title="5    zookeeper如何管理kafka"></a>5    zookeeper如何管理kafka</h2><ol>
<li>Producer端使用zookeeper用来”发现”broker列表,以及和Topic下每个partition leader建立socket连接并发送消息.</li>
<li>Broker端使用zookeeper用来注册broker信息,以及监测partition leader存活性.</li>
<li>Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息.    </li>
</ol>
<h2 id="6-补充问题，kafka能否自动创建topics"><a href="#6-补充问题，kafka能否自动创建topics" class="headerlink" title="6    补充问题，kafka能否自动创建topics"></a>6    补充问题，kafka能否自动创建topics</h2><p>  producer.properties配置文件中的一个参数:<strong><em>auto.create.topics.enable=true</em></strong><br>  是否自动创建<br>  如果broker中没有topic的信息,当producer/consumer操作topic时,是否自动创建.<br>  如果为false,则只能通过API或者command创建topic  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shartoo.github.com/2019/12/23/2016-03-10-kafkaquestion/" data-id="ck4ifp1lh000r2wje9imh1qzf" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/12/23/2016-03-12-spark-envirnoment/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          spark环境部署
        
      </div>
    </a>
  
  
    <a href="/2019/12/23/2016-03-09-bigdata-cluster-opt/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">大数据：集群优化</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/12/23/template/">博客题目</a>
          </li>
        
          <li>
            <a href="/2019/12/23/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-11-26-model-pruning/">模型剪枝和优化-torch和Tensorflow为例</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-10-28--understand-pytorch/">理解pytorch的计算逻辑</a>
          </li>
        
          <li>
            <a href="/2019/12/23/2019-09-24-outlier-detection/">使用pyod做离群点检测</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 shartoo<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>